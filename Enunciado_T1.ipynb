{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Problemas de clasificación y  regresión.\n",
    "* Selección de atributos y parámetros de regularización en regresión lineal (Ridge y Lasso).\n",
    "* Validación cruzada.\n",
    "* PCA e ICA versus LDA. Reducción de dimensionalidad para clasificación.\n",
    "* Selección de hı́per-parámetros estructurales en Regresión Logı́stica y Perceptrón.\n",
    "* LDA, QDA, Naive Bayes en texto, clasificadores bayesianos ingenuos (Bernoulli, Multinomial)\n",
    "* Preprocesamiento de datos brutos y representaciones de entrada.\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 26 de Octubre y 29 de Octubre respectivamente.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF393-II-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Aprendizaje con regresión lineal  \n",
    "[2.](#segundo) Análisis de audios como datos brutos  \n",
    "[3.](#tercero) Análisis de emociones en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Aprendizaje con regresión lineal.\n",
    "\n",
    "El modelo de regresión lineal  es una combinación lineal entre variables independientes para obtener otra variable, dependiente de éstas. Lo cual puede resultar bastante simple, pero, hoy en día, ha podido ser aplicado a varios problemas con buenos resultados, como predicción en finanzas y en medicina. Sin embargo, también puede ser un medio para aplicar un modelo más grande, por ejemplo utilizarlo para que, con el resuido, detectar *outliers*, rellenar vacíos/datos incompletos o aprender un *score* para ranquear objetos, lo que haremos en esta sección.\n",
    "\n",
    "<img src=\"http://chanakya.ca/wp-content/uploads/2018/05/EstimateMultipleLinearRegressionCoefficientsExample_01.png\" height=\"15%\" />\n",
    "\n",
    "\n",
    "El problema de *learning to rank* es aplicado comúnmente en *Information Retrieval* (IR). Sin embargo, el aprender ésta función puede ser crucial para modelar la importancia de distintos objetos.  \n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con el problema de predecir el *ranking* mundial de una Universidad en base a distintas características de ésta (dataset *World University Rankings*, a través del siguiente __[link](https://www.kaggle.com/mylesoneill/world-university-rankings)__) en la plataforma de *Kaggle*. En este problema el *ranking* es una medición de qué tan buena es la universidad e intentaremos predecirla a través un modelo simple de regresión lineal. En particular, dentro de los miles de diferentes sistemas de rankings, nacionales e internacionales, entre los cuales comúnmente existen desacuerdos entre ellos, trabajaremos con el ranking ampliamente considerado como uno de las más influyentes y ampliamente observadas: *Times Higher Education World University* .\n",
    "\n",
    "\n",
    "> a) Cargue los datos a analizar, descargándolos desde la plataforma como se indicó, en formato *dataframe pandas*. Descríbalos adecuadamente, ya sea la variable dependiente o las independientes, si es que lo son.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"world-university-rankings/timesData.csv\")\n",
    "df.shape\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "> b) Debido a la estructura será necesario realizar un leve pre-proceso. Existen vacíos entre los datos o valores '-', por lo que será necesario eliminarlos (*o si piensa una mejor manera de manejar ésto puede hacerlo, se verá reflejado en su nota*). Además de ésto deje los datos con *score unkown* o '-' en un conjunto *target* separado, *unlabeled data* (éste será el objetivo del entrenamiento) ¿Cuántos datos quedan en cada conjunto? \n",
    "```python\n",
    "def convertToInt(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x\n",
    "df.dropna(axis=0,inplace=True,how='any') #borra nan\n",
    "df[\"total_score\"] = df3[\"total_score\"].apply(lambda x: x.replace('-','unknown')) #rellena \n",
    "df = df[~(df == '-').any(axis=1)] #elimina filas con valores nulos\n",
    "...\n",
    "nuevo_df  = pd.get_dummies(df, columns=[\"country\"]) #column to categorical\n",
    "....\n",
    "nuevo_df['female'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[0].apply(convertToInt)\n",
    "nuevo_df['male'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[1].apply(convertToInt)\n",
    "nuevo_df['female_male_ratio'] =  np.where(nuevo_df['male'] == 0, 0, nuevo_df['female']/nuevo_df['male']) #si no hay (rellena 0) \n",
    "nuevo_df['num_students'] = nuevo_df['num_students'].apply(lambda x: int(str(x).replace(',','')))\n",
    "nuevo_df['international_students'] = nuevo_df['international_students'].apply(lambda x: int(str(x).replace('%','')))\n",
    "print(nuevo_df.shape)\n",
    "...\n",
    "df_test = nuevo_df[nuevo_df[\"total_score\"]=='unknown']  #para predecir al final\n",
    "nuevo_df =  nuevo_df[nuevo_df[\"total_score\"]!='unknown'] #elimina unknown rank..\n",
    "print(nuevo_df.shape)\n",
    "nuevo_df.head()\n",
    "```\n",
    "\n",
    "> c) Cree las matrices de cada conjunto con las que trabajará. Además de ésto separe el conjunto de pruebas fijo que se utilizará, recuerde que éste no puede ser utilizado. Si estima conveniente también cree conjunto de validación.\n",
    "```python\n",
    "Y = nuevo_df['total_score'].values\n",
    "X = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "X_test = df_test.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "Y = Y.astype('float32')\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X.shape\n",
    "...\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "...\n",
    "validation_set = #if you want to create val!\n",
    "```\n",
    "\n",
    "> d) Normalice los datos antes de trabajar. Explique la importancia/conveniencia de realizar ésto.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "> e) Realice una regresión lineal de mı́nimos cuadrados básica. Mida el residuo de cada predicción en cada dato y haga un gráfico de éste ¿Qué indica lo observado?\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "...\n",
    "import seaborn as sns\n",
    "res = y_train-linreg.predict(X_train_scaled)\n",
    "sns.distplot(res)\n",
    "```\n",
    "\n",
    "> f) Construya una tabla con los pesos, Z-score y F-score correspondientes a cada predictor (variable), compare estos valores. ¿Qué sucede si hacemos un raking de los atributos en base al peso obtenido en la regresión? Compare y comente ¿Qué variables están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo que observa y cuál puede ser la causa?\n",
    "\n",
    "> g) Calcule la información mútua de los distintos predictores (variables) con respecto a la variable *output* o *target*. Comente con lo calculado anteriormente y se le parece razonable.\n",
    "```python\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "minfo_predictor = mutual_info_regression(X,y)\n",
    "```\n",
    "\n",
    "> h)  Construya una función que implemente *Forward Step-wise Selection* (FSS). Es decir, partiendo con un modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo. Ordene el eje $x$ de menor a mayor.\n",
    "```python\n",
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = LR(fit_intercept=True, n_jobs=1)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    return selected\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "fss(X_train_scaled,y_train,names_regressors)\n",
    "```\n",
    "\n",
    "> i) Ajuste un modelo lineal utilizando “*Ridge Regression*”, es decir, regularizando con la norma $l_2$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^0, 10^6$], variando si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Deje un gráfico sólo para analizar los coeficientes de los países. Describa lo que observa.\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "alphas_ = np.logspace(0,6,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    if \"country\" not in label:\n",
    "        plt.plot(alphas_, y_arr, label=label)\n",
    "ax.set_xscale('log')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "...#modify\n",
    "if \"country\" in label:\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.title('Regularization Path RIDGE of country coefs')\n",
    "```\n",
    "\n",
    "> j) Ajuste un modelo lineal utilizando el método “*Lasso*”, es decir, regularizando con la norma $l_1$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^{-2},10^3$]. Para obtener el código, modifique el ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo *Lasso* para seleccionar atributos?\n",
    "```python\n",
    "from sklearn.linear_model import Lasso\n",
    "alphas_ = np.logspace(-2,3,base=10)\n",
    "model = Lasso(fit_intercept=True)\n",
    "...\n",
    "country_alphas_ = np.logspace(-5,0,base=10)\n",
    "```\n",
    "> k) Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un gráfico que muestre el error de entrenamiento y el de pruebas como función del parámetro de regularización. Discuta lo que  observa.\n",
    "```python\n",
    "alphas_ = #choose it\n",
    "coefs = []\n",
    "model = #choose it\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    yhat_train = model.predict(X_train_scaled)\n",
    "    yhat_test = model.predict(X_test_scaled)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - y_train, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - y_test, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge/lasso')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge/lasso')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> l) Estime el valor del parámetro de regularización en **alguno** de los modelos anteriores haciendo uso de la técnica validación cruzada con un número de folds igual a $K= 5$ y $K = 10$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Mida el error real del modelo (ésto es sobre el conjunto de pruebas). Debido a la escala del error puede utilizar auxiliarmente *MAE* como métrica de desempeño. Compare y concluya.\n",
    "```python\n",
    "yhat_test = linreg.predict(X_test_scaled)\n",
    "mse_test = np.mean(np.power(yhat_test - y_test, 2))\n",
    "from sklearn.model_selection import KFold\n",
    "K=10\n",
    "kf = KFold(n_splits=K)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(X_train_scaled):\n",
    "    linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "    linreg.fit(X_train_scaled[train], y_train[train])\n",
    "    yhat_kfold_val = linreg.predict(X_train_scaled[val])\n",
    "    mse_fold = np.mean(np.power(yhat_kfold_val - y_train[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / K\n",
    "...#or MAE\n",
    "mae_fold = np.mean(np.abs(yhat_kfold_val - y_train[val]))\n",
    "```\n",
    "\n",
    "> m) Con el modelo que se piense que es el mejor, en base a todo lo experimentado. Realice el *ranking* de las universidades del que no se tienen etiquetas (*unlabeled data* o *target data*) a través de predecir los datos que se dejaron como *pruebas* y ordenar su score en el *dataframe*.\n",
    "```python\n",
    "df_test[\"total_score\"] = model.predict(X_test_scaled) #predict score\n",
    "...#armar un raking\n",
    "univ_chilenas = df_test[df_test[\"country_Chile\"]==1]\n",
    "rannking_univ_ch = univ_chilenas.sort_values(by=\"total_score\",ascending=False)\n",
    "ranking = 1\n",
    "for index,row in rannking_univ_ch.iterrows():\n",
    "    print(\"%d - Institucion: %s\" %(ranking,row[\"university_name\"]))\n",
    "    ranking+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>country</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>total_score</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>international_students</th>\n",
       "      <th>female_male_ratio</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>99.7</td>\n",
       "      <td>72.4</td>\n",
       "      <td>98.7</td>\n",
       "      <td>98.8</td>\n",
       "      <td>34.5</td>\n",
       "      <td>96.1</td>\n",
       "      <td>20,152</td>\n",
       "      <td>8.9</td>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2,243</td>\n",
       "      <td>6.9</td>\n",
       "      <td>27%</td>\n",
       "      <td>33 : 67</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>95.6</td>\n",
       "      <td>11,074</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33%</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>94.3</td>\n",
       "      <td>15,596</td>\n",
       "      <td>7.8</td>\n",
       "      <td>22%</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>90.9</td>\n",
       "      <td>70.3</td>\n",
       "      <td>95.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>-</td>\n",
       "      <td>94.2</td>\n",
       "      <td>7,929</td>\n",
       "      <td>8.4</td>\n",
       "      <td>27%</td>\n",
       "      <td>45 : 55</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>91.2</td>\n",
       "      <td>18,812</td>\n",
       "      <td>11.8</td>\n",
       "      <td>34%</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>91.2</td>\n",
       "      <td>19,919</td>\n",
       "      <td>11.6</td>\n",
       "      <td>34%</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>84.2</td>\n",
       "      <td>39.6</td>\n",
       "      <td>99.3</td>\n",
       "      <td>97.8</td>\n",
       "      <td>-</td>\n",
       "      <td>91.1</td>\n",
       "      <td>36,186</td>\n",
       "      <td>16.4</td>\n",
       "      <td>15%</td>\n",
       "      <td>50 : 50</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>89.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>92.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>15,060</td>\n",
       "      <td>11.7</td>\n",
       "      <td>51%</td>\n",
       "      <td>37 : 63</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>92.1</td>\n",
       "      <td>59.2</td>\n",
       "      <td>89.7</td>\n",
       "      <td>91.5</td>\n",
       "      <td>-</td>\n",
       "      <td>89.5</td>\n",
       "      <td>11,751</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20%</td>\n",
       "      <td>50 : 50</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>83.0</td>\n",
       "      <td>48.1</td>\n",
       "      <td>92.9</td>\n",
       "      <td>93.2</td>\n",
       "      <td>-</td>\n",
       "      <td>87.7</td>\n",
       "      <td>38,206</td>\n",
       "      <td>10.3</td>\n",
       "      <td>15%</td>\n",
       "      <td>52 : 48</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>University of Chicago</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>79.1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>-</td>\n",
       "      <td>86.9</td>\n",
       "      <td>14,221</td>\n",
       "      <td>6.9</td>\n",
       "      <td>21%</td>\n",
       "      <td>42 : 58</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>80.9</td>\n",
       "      <td>58.5</td>\n",
       "      <td>89.2</td>\n",
       "      <td>92.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.4</td>\n",
       "      <td>15,128</td>\n",
       "      <td>3.6</td>\n",
       "      <td>23%</td>\n",
       "      <td>50 : 50</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Cornell University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>82.2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>88.8</td>\n",
       "      <td>88.1</td>\n",
       "      <td>34.7</td>\n",
       "      <td>83.9</td>\n",
       "      <td>21,424</td>\n",
       "      <td>10.2</td>\n",
       "      <td>19%</td>\n",
       "      <td>48 : 52</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>ETH Zurich – Swiss Federal Institute of Techno...</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>77.5</td>\n",
       "      <td>93.7</td>\n",
       "      <td>87.8</td>\n",
       "      <td>83.1</td>\n",
       "      <td>-</td>\n",
       "      <td>83.4</td>\n",
       "      <td>18,178</td>\n",
       "      <td>14.7</td>\n",
       "      <td>37%</td>\n",
       "      <td>31 : 69</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>83.9</td>\n",
       "      <td>53.3</td>\n",
       "      <td>89.1</td>\n",
       "      <td>84.1</td>\n",
       "      <td>59.6</td>\n",
       "      <td>83.4</td>\n",
       "      <td>41,786</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16%</td>\n",
       "      <td>48 : 52</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>University of Toronto</td>\n",
       "      <td>Canada</td>\n",
       "      <td>75.8</td>\n",
       "      <td>-</td>\n",
       "      <td>87.9</td>\n",
       "      <td>82.2</td>\n",
       "      <td>-</td>\n",
       "      <td>82.0</td>\n",
       "      <td>66,198</td>\n",
       "      <td>19.5</td>\n",
       "      <td>15%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>73.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>73.8</td>\n",
       "      <td>92.6</td>\n",
       "      <td>-</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25,055</td>\n",
       "      <td>5.9</td>\n",
       "      <td>28%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>71.8</td>\n",
       "      <td>32.9</td>\n",
       "      <td>82.7</td>\n",
       "      <td>93.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>79.5</td>\n",
       "      <td>20,376</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20%</td>\n",
       "      <td>51 : 49</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>70.3</td>\n",
       "      <td>39.1</td>\n",
       "      <td>79.3</td>\n",
       "      <td>95.7</td>\n",
       "      <td>53.7</td>\n",
       "      <td>79.3</td>\n",
       "      <td>11,885</td>\n",
       "      <td>13.1</td>\n",
       "      <td>35%</td>\n",
       "      <td>39 : 61</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>University of Hong Kong</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>68.4</td>\n",
       "      <td>91.4</td>\n",
       "      <td>71.4</td>\n",
       "      <td>96.1</td>\n",
       "      <td>56.5</td>\n",
       "      <td>79.2</td>\n",
       "      <td>19,835</td>\n",
       "      <td>17.6</td>\n",
       "      <td>38%</td>\n",
       "      <td>53 : 47</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>University College London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>74.0</td>\n",
       "      <td>90.8</td>\n",
       "      <td>81.6</td>\n",
       "      <td>80.6</td>\n",
       "      <td>39.0</td>\n",
       "      <td>78.4</td>\n",
       "      <td>26,607</td>\n",
       "      <td>10.7</td>\n",
       "      <td>46%</td>\n",
       "      <td>56 : 44</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>University of Washington</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>68.2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>95.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44,020</td>\n",
       "      <td>11.8</td>\n",
       "      <td>13%</td>\n",
       "      <td>53 : 47</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>66.8</td>\n",
       "      <td>49.4</td>\n",
       "      <td>71.5</td>\n",
       "      <td>92.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>15,172</td>\n",
       "      <td>4.8</td>\n",
       "      <td>17%</td>\n",
       "      <td>49 : 51</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>64.5</td>\n",
       "      <td>60.5</td>\n",
       "      <td>68.8</td>\n",
       "      <td>95.3</td>\n",
       "      <td>-</td>\n",
       "      <td>75.9</td>\n",
       "      <td>18,334</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15%</td>\n",
       "      <td>48 : 52</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>University of Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>87.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>91.9</td>\n",
       "      <td>58.1</td>\n",
       "      <td>-</td>\n",
       "      <td>75.6</td>\n",
       "      <td>26,199</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Georgia Institute of Technology</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>67.9</td>\n",
       "      <td>73.2</td>\n",
       "      <td>72.6</td>\n",
       "      <td>83.2</td>\n",
       "      <td>95.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>19,967</td>\n",
       "      <td>20.1</td>\n",
       "      <td>26%</td>\n",
       "      <td>31 : 69</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Pohang University of Science and Technology</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>69.5</td>\n",
       "      <td>32.6</td>\n",
       "      <td>62.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>3,055</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4%</td>\n",
       "      <td>20 : 80</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>University of California, Santa Barbara</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>56.6</td>\n",
       "      <td>64.3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>89.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>22,020</td>\n",
       "      <td>27.3</td>\n",
       "      <td>11%</td>\n",
       "      <td>52 : 48</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>Canada</td>\n",
       "      <td>65.1</td>\n",
       "      <td>93.3</td>\n",
       "      <td>74.8</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42.6</td>\n",
       "      <td>73.8</td>\n",
       "      <td>50,152</td>\n",
       "      <td>17.6</td>\n",
       "      <td>25%</td>\n",
       "      <td>54 : 46</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of Tehran</td>\n",
       "      <td>Iran</td>\n",
       "      <td>26.1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>15.8</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>53,802</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1%</td>\n",
       "      <td>45 : 55</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of Texas at El Paso</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>18.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>19,123</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7%</td>\n",
       "      <td>54 : 46</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Texas Tech University</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>27.9</td>\n",
       "      <td>36.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>29,512</td>\n",
       "      <td>20.9</td>\n",
       "      <td>7%</td>\n",
       "      <td>46 : 54</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tokai University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>17.9</td>\n",
       "      <td>19.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>-</td>\n",
       "      <td>29,700</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1%</td>\n",
       "      <td>27 : 73</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tokushima University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>25.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>59.6</td>\n",
       "      <td>-</td>\n",
       "      <td>7,519</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3%</td>\n",
       "      <td>34 : 66</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tokyo University of Marine Science and Technology</td>\n",
       "      <td>Japan</td>\n",
       "      <td>27.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>57.9</td>\n",
       "      <td>-</td>\n",
       "      <td>2,597</td>\n",
       "      <td>11.1</td>\n",
       "      <td>7%</td>\n",
       "      <td>34 : 66</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tokyo University of Science</td>\n",
       "      <td>Japan</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>37.6</td>\n",
       "      <td>-</td>\n",
       "      <td>20,243</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2%</td>\n",
       "      <td>20 : 80</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tomsk State University</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>34.8</td>\n",
       "      <td>36.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-</td>\n",
       "      <td>10,413</td>\n",
       "      <td>9.9</td>\n",
       "      <td>12%</td>\n",
       "      <td>60 : 40</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Tottori University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>24.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>10.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-</td>\n",
       "      <td>6,248</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2%</td>\n",
       "      <td>34 : 66</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Toyohashi University of Technology</td>\n",
       "      <td>Japan</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>15.8</td>\n",
       "      <td>50.3</td>\n",
       "      <td>-</td>\n",
       "      <td>2,153</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9%</td>\n",
       "      <td>9 : 91</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Universiti Kebangsaan Malaysia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>24.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>28.4</td>\n",
       "      <td>-</td>\n",
       "      <td>24,227</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12%</td>\n",
       "      <td>62 : 38</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Universiti Putra Malaysia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>25.3</td>\n",
       "      <td>50.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>34.2</td>\n",
       "      <td>-</td>\n",
       "      <td>23,883</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16%</td>\n",
       "      <td>63 : 37</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Universiti Sains Malaysia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>26.9</td>\n",
       "      <td>44.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>-</td>\n",
       "      <td>28,179</td>\n",
       "      <td>14.8</td>\n",
       "      <td>10%</td>\n",
       "      <td>61 : 39</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Universiti Teknologi MARA</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>15.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>18.2</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-</td>\n",
       "      <td>69,268</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0%</td>\n",
       "      <td>65 : 35</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Ural Federal University</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>24.8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>10.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>35.6</td>\n",
       "      <td>-</td>\n",
       "      <td>28,427</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3%</td>\n",
       "      <td>48 : 52</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>601-800</td>\n",
       "      <td>V.N. Karazin Kharkiv National University</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>21.7</td>\n",
       "      <td>48.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>-</td>\n",
       "      <td>14,410</td>\n",
       "      <td>9.7</td>\n",
       "      <td>22%</td>\n",
       "      <td>53 : 47</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of Vigo</td>\n",
       "      <td>Spain</td>\n",
       "      <td>18.4</td>\n",
       "      <td>30.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>38.1</td>\n",
       "      <td>-</td>\n",
       "      <td>22,793</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3%</td>\n",
       "      <td>51 : 49</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Vilnius University</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>18.3</td>\n",
       "      <td>40.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-</td>\n",
       "      <td>19,019</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4%</td>\n",
       "      <td>65 : 35</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Warsaw University of Technology</td>\n",
       "      <td>Poland</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>40.3</td>\n",
       "      <td>47.4</td>\n",
       "      <td>-</td>\n",
       "      <td>34,572</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3%</td>\n",
       "      <td>34 : 66</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Waseda University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>23.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>32.4</td>\n",
       "      <td>-</td>\n",
       "      <td>52,316</td>\n",
       "      <td>16.9</td>\n",
       "      <td>8%</td>\n",
       "      <td>35 : 65</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of West Bohemia</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>16.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>29.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>-</td>\n",
       "      <td>15,639</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2%</td>\n",
       "      <td>52 : 48</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of the West of England</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>16.9</td>\n",
       "      <td>48.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>34.6</td>\n",
       "      <td>28.5</td>\n",
       "      <td>-</td>\n",
       "      <td>22,525</td>\n",
       "      <td>21.4</td>\n",
       "      <td>15%</td>\n",
       "      <td>53 : 47</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>601-800</td>\n",
       "      <td>West University of Timişoara</td>\n",
       "      <td>Romania</td>\n",
       "      <td>16.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>12,933</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3%</td>\n",
       "      <td>62 : 38</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>601-800</td>\n",
       "      <td>University of Westminster</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17.3</td>\n",
       "      <td>81.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>-</td>\n",
       "      <td>16,609</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43%</td>\n",
       "      <td>57 : 43</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Xidian University</td>\n",
       "      <td>China</td>\n",
       "      <td>17.9</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>-</td>\n",
       "      <td>31,618</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2%</td>\n",
       "      <td>29 : 71</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Yeungnam University</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>18.6</td>\n",
       "      <td>24.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>35.4</td>\n",
       "      <td>-</td>\n",
       "      <td>21,958</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3%</td>\n",
       "      <td>48 : 52</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Yıldız Technical University</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-</td>\n",
       "      <td>31,268</td>\n",
       "      <td>28.7</td>\n",
       "      <td>2%</td>\n",
       "      <td>36 : 64</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Yokohama City University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>37.9</td>\n",
       "      <td>-</td>\n",
       "      <td>4,122</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Yokohama National University</td>\n",
       "      <td>Japan</td>\n",
       "      <td>20.1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>40.4</td>\n",
       "      <td>-</td>\n",
       "      <td>10,117</td>\n",
       "      <td>12.1</td>\n",
       "      <td>8%</td>\n",
       "      <td>28 : 72</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>601-800</td>\n",
       "      <td>Yuan Ze University</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>16.2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>28.6</td>\n",
       "      <td>39.8</td>\n",
       "      <td>-</td>\n",
       "      <td>8,663</td>\n",
       "      <td>20.6</td>\n",
       "      <td>4%</td>\n",
       "      <td>43 : 57</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2603 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     world_rank                                    university_name  \\\n",
       "0             1                                 Harvard University   \n",
       "1             2                 California Institute of Technology   \n",
       "2             3              Massachusetts Institute of Technology   \n",
       "3             4                                Stanford University   \n",
       "4             5                               Princeton University   \n",
       "5             6                            University of Cambridge   \n",
       "6             6                               University of Oxford   \n",
       "7             8                 University of California, Berkeley   \n",
       "8             9                            Imperial College London   \n",
       "9            10                                    Yale University   \n",
       "10           11              University of California, Los Angeles   \n",
       "11           12                              University of Chicago   \n",
       "12           13                           Johns Hopkins University   \n",
       "13           14                                 Cornell University   \n",
       "14           15  ETH Zurich – Swiss Federal Institute of Techno...   \n",
       "15           15                             University of Michigan   \n",
       "16           17                              University of Toronto   \n",
       "17           18                                Columbia University   \n",
       "18           19                         University of Pennsylvania   \n",
       "19           20                         Carnegie Mellon University   \n",
       "20           21                            University of Hong Kong   \n",
       "21           22                          University College London   \n",
       "22           23                           University of Washington   \n",
       "23           24                                    Duke University   \n",
       "24           25                            Northwestern University   \n",
       "25           26                                University of Tokyo   \n",
       "26           27                    Georgia Institute of Technology   \n",
       "27           28        Pohang University of Science and Technology   \n",
       "28           29            University of California, Santa Barbara   \n",
       "29           30                     University of British Columbia   \n",
       "...         ...                                                ...   \n",
       "2573    601-800                               University of Tehran   \n",
       "2574    601-800                     University of Texas at El Paso   \n",
       "2575    601-800                              Texas Tech University   \n",
       "2576    601-800                                   Tokai University   \n",
       "2577    601-800                               Tokushima University   \n",
       "2578    601-800  Tokyo University of Marine Science and Technology   \n",
       "2579    601-800                        Tokyo University of Science   \n",
       "2580    601-800                             Tomsk State University   \n",
       "2581    601-800                                 Tottori University   \n",
       "2582    601-800                 Toyohashi University of Technology   \n",
       "2583    601-800                     Universiti Kebangsaan Malaysia   \n",
       "2584    601-800                          Universiti Putra Malaysia   \n",
       "2585    601-800                          Universiti Sains Malaysia   \n",
       "2586    601-800                          Universiti Teknologi MARA   \n",
       "2587    601-800                            Ural Federal University   \n",
       "2588    601-800           V.N. Karazin Kharkiv National University   \n",
       "2589    601-800                                 University of Vigo   \n",
       "2590    601-800                                 Vilnius University   \n",
       "2591    601-800                    Warsaw University of Technology   \n",
       "2592    601-800                                  Waseda University   \n",
       "2593    601-800                         University of West Bohemia   \n",
       "2594    601-800                  University of the West of England   \n",
       "2595    601-800                       West University of Timişoara   \n",
       "2596    601-800                          University of Westminster   \n",
       "2597    601-800                                  Xidian University   \n",
       "2598    601-800                                Yeungnam University   \n",
       "2599    601-800                        Yıldız Technical University   \n",
       "2600    601-800                           Yokohama City University   \n",
       "2601    601-800                       Yokohama National University   \n",
       "2602    601-800                                 Yuan Ze University   \n",
       "\n",
       "                       country  teaching international  research  citations  \\\n",
       "0     United States of America      99.7          72.4      98.7       98.8   \n",
       "1     United States of America      97.7          54.6      98.0       99.9   \n",
       "2     United States of America      97.8          82.3      91.4       99.9   \n",
       "3     United States of America      98.3          29.5      98.1       99.2   \n",
       "4     United States of America      90.9          70.3      95.4       99.9   \n",
       "5               United Kingdom      90.5          77.7      94.1       94.0   \n",
       "6               United Kingdom      88.2          77.2      93.9       95.1   \n",
       "7     United States of America      84.2          39.6      99.3       97.8   \n",
       "8               United Kingdom      89.2          90.0      94.5       88.3   \n",
       "9     United States of America      92.1          59.2      89.7       91.5   \n",
       "10    United States of America      83.0          48.1      92.9       93.2   \n",
       "11    United States of America      79.1          62.8      87.9       96.9   \n",
       "12    United States of America      80.9          58.5      89.2       92.3   \n",
       "13    United States of America      82.2          62.4      88.8       88.1   \n",
       "14                 Switzerland      77.5          93.7      87.8       83.1   \n",
       "15    United States of America      83.9          53.3      89.1       84.1   \n",
       "16                      Canada      75.8             -      87.9       82.2   \n",
       "17    United States of America      73.8          90.9      73.8       92.6   \n",
       "18    United States of America      71.8          32.9      82.7       93.6   \n",
       "19    United States of America      70.3          39.1      79.3       95.7   \n",
       "20                   Hong Kong      68.4          91.4      71.4       96.1   \n",
       "21              United Kingdom      74.0          90.8      81.6       80.6   \n",
       "22    United States of America      68.2          49.0      77.1       95.9   \n",
       "23    United States of America      66.8          49.4      71.5       92.3   \n",
       "24    United States of America      64.5          60.5      68.8       95.3   \n",
       "25                       Japan      87.7          18.4      91.9       58.1   \n",
       "26    United States of America      67.9          73.2      72.6       83.2   \n",
       "27                 South Korea      69.5          32.6      62.5       96.5   \n",
       "28    United States of America      56.6          64.3      68.0       98.8   \n",
       "29                      Canada      65.1          93.3      74.8       80.3   \n",
       "...                        ...       ...           ...       ...        ...   \n",
       "2573                      Iran      26.1          16.5      16.9       15.8   \n",
       "2574  United States of America      18.6          30.4      18.7       18.4   \n",
       "2575  United States of America      27.9          36.8      17.2       22.0   \n",
       "2576                     Japan      17.9          19.3       7.6       15.3   \n",
       "2577                     Japan      25.3          16.8      21.6       12.8   \n",
       "2578                     Japan      27.9          24.5      12.4        7.7   \n",
       "2579                     Japan      23.0          15.4      24.1       21.4   \n",
       "2580        Russian Federation      34.8          36.9      20.8        7.6   \n",
       "2581                     Japan      24.3          16.7      10.1        9.6   \n",
       "2582                     Japan      22.0          25.4      18.9       15.8   \n",
       "2583                  Malaysia      24.3          29.7      15.9       10.9   \n",
       "2584                  Malaysia      25.3          50.1      20.9       10.2   \n",
       "2585                  Malaysia      26.9          44.2      16.6       12.4   \n",
       "2586                  Malaysia      15.2          14.8       7.7       18.2   \n",
       "2587        Russian Federation      24.8          17.3      10.6       16.8   \n",
       "2588                   Ukraine      21.7          48.4       8.9        1.7   \n",
       "2589                     Spain      18.4          30.7      10.5       31.8   \n",
       "2590                 Lithuania      18.3          40.8      13.6       26.1   \n",
       "2591                    Poland      19.4          20.7       8.5       40.3   \n",
       "2592                     Japan      23.6          29.7      14.6       29.4   \n",
       "2593            Czech Republic      16.3          23.1       9.7       29.8   \n",
       "2594            United Kingdom      16.9          48.5      11.2       34.6   \n",
       "2595                   Romania      16.1          21.0       3.9       22.4   \n",
       "2596            United Kingdom      17.3          81.9      11.7       21.1   \n",
       "2597                     China      17.9          12.8      12.1        8.9   \n",
       "2598               South Korea      18.6          24.3      10.9       26.5   \n",
       "2599                    Turkey      14.5          14.9       7.6       19.3   \n",
       "2600                     Japan      24.0          16.1      10.2       36.4   \n",
       "2601                     Japan      20.1          23.3      16.0       13.5   \n",
       "2602                    Taiwan      16.2          17.7      18.3       28.6   \n",
       "\n",
       "     income total_score num_students  student_staff_ratio  \\\n",
       "0      34.5        96.1       20,152                  8.9   \n",
       "1      83.7        96.0        2,243                  6.9   \n",
       "2      87.5        95.6       11,074                  9.0   \n",
       "3      64.3        94.3       15,596                  7.8   \n",
       "4         -        94.2        7,929                  8.4   \n",
       "5      57.0        91.2       18,812                 11.8   \n",
       "6      73.5        91.2       19,919                 11.6   \n",
       "7         -        91.1       36,186                 16.4   \n",
       "8      92.9        90.6       15,060                 11.7   \n",
       "9         -        89.5       11,751                  4.4   \n",
       "10        -        87.7       38,206                 10.3   \n",
       "11        -        86.9       14,221                  6.9   \n",
       "12    100.0        86.4       15,128                  3.6   \n",
       "13     34.7        83.9       21,424                 10.2   \n",
       "14        -        83.4       18,178                 14.7   \n",
       "15     59.6        83.4       41,786                  9.0   \n",
       "16        -        82.0       66,198                 19.5   \n",
       "17        -        81.0       25,055                  5.9   \n",
       "18     43.7        79.5       20,376                  6.5   \n",
       "19     53.7        79.3       11,885                 13.1   \n",
       "20     56.5        79.2       19,835                 17.6   \n",
       "21     39.0        78.4       26,607                 10.7   \n",
       "22     32.8        78.0       44,020                 11.8   \n",
       "23    100.0        76.5       15,172                  4.8   \n",
       "24        -        75.9       18,334                 13.8   \n",
       "25        -        75.6       26,199                  5.7   \n",
       "26     95.1        75.3       19,967                 20.1   \n",
       "27    100.0        75.1        3,055                 10.1   \n",
       "28     89.8        75.0       22,020                 27.3   \n",
       "29     42.6        73.8       50,152                 17.6   \n",
       "...     ...         ...          ...                  ...   \n",
       "2573      -           -       53,802                 27.0   \n",
       "2574      -           -       19,123                 29.0   \n",
       "2575      -           -       29,512                 20.9   \n",
       "2576   34.4           -       29,700                 12.7   \n",
       "2577   59.6           -        7,519                  8.9   \n",
       "2578   57.9           -        2,597                 11.1   \n",
       "2579   37.6           -       20,243                 25.7   \n",
       "2580   44.0           -       10,413                  9.9   \n",
       "2581   34.5           -        6,248                  8.2   \n",
       "2582   50.3           -        2,153                  9.3   \n",
       "2583   28.4           -       24,227                 11.8   \n",
       "2584   34.2           -       23,883                 12.2   \n",
       "2585   34.4           -       28,179                 14.8   \n",
       "2586   28.3           -       69,268                 16.8   \n",
       "2587   35.6           -       28,427                 10.1   \n",
       "2588   28.8           -       14,410                  9.7   \n",
       "2589   38.1           -       22,793                 19.0   \n",
       "2590   41.0           -       19,019                 14.2   \n",
       "2591   47.4           -       34,572                 14.5   \n",
       "2592   32.4           -       52,316                 16.9   \n",
       "2593   32.1           -       15,639                 21.5   \n",
       "2594   28.5           -       22,525                 21.4   \n",
       "2595      -           -       12,933                 19.0   \n",
       "2596   28.5           -       16,609                 21.0   \n",
       "2597   83.7           -       31,618                 16.4   \n",
       "2598   35.4           -       21,958                 15.3   \n",
       "2599   44.0           -       31,268                 28.7   \n",
       "2600   37.9           -        4,122                  3.7   \n",
       "2601   40.4           -       10,117                 12.1   \n",
       "2602   39.8           -        8,663                 20.6   \n",
       "\n",
       "     international_students female_male_ratio  year  \n",
       "0                       25%               NaN  2011  \n",
       "1                       27%           33 : 67  2011  \n",
       "2                       33%           37 : 63  2011  \n",
       "3                       22%           42 : 58  2011  \n",
       "4                       27%           45 : 55  2011  \n",
       "5                       34%           46 : 54  2011  \n",
       "6                       34%           46 : 54  2011  \n",
       "7                       15%           50 : 50  2011  \n",
       "8                       51%           37 : 63  2011  \n",
       "9                       20%           50 : 50  2011  \n",
       "10                      15%           52 : 48  2011  \n",
       "11                      21%           42 : 58  2011  \n",
       "12                      23%           50 : 50  2011  \n",
       "13                      19%           48 : 52  2011  \n",
       "14                      37%           31 : 69  2011  \n",
       "15                      16%           48 : 52  2011  \n",
       "16                      15%               NaN  2011  \n",
       "17                      28%               NaN  2011  \n",
       "18                      20%           51 : 49  2011  \n",
       "19                      35%           39 : 61  2011  \n",
       "20                      38%           53 : 47  2011  \n",
       "21                      46%           56 : 44  2011  \n",
       "22                      13%           53 : 47  2011  \n",
       "23                      17%           49 : 51  2011  \n",
       "24                      15%           48 : 52  2011  \n",
       "25                      10%               NaN  2011  \n",
       "26                      26%           31 : 69  2011  \n",
       "27                       4%           20 : 80  2011  \n",
       "28                      11%           52 : 48  2011  \n",
       "29                      25%           54 : 46  2011  \n",
       "...                     ...               ...   ...  \n",
       "2573                     1%           45 : 55  2016  \n",
       "2574                     7%           54 : 46  2016  \n",
       "2575                     7%           46 : 54  2016  \n",
       "2576                     1%           27 : 73  2016  \n",
       "2577                     3%           34 : 66  2016  \n",
       "2578                     7%           34 : 66  2016  \n",
       "2579                     2%           20 : 80  2016  \n",
       "2580                    12%           60 : 40  2016  \n",
       "2581                     2%           34 : 66  2016  \n",
       "2582                     9%            9 : 91  2016  \n",
       "2583                    12%           62 : 38  2016  \n",
       "2584                    16%           63 : 37  2016  \n",
       "2585                    10%           61 : 39  2016  \n",
       "2586                     0%           65 : 35  2016  \n",
       "2587                     3%           48 : 52  2016  \n",
       "2588                    22%           53 : 47  2016  \n",
       "2589                     3%           51 : 49  2016  \n",
       "2590                     4%           65 : 35  2016  \n",
       "2591                     3%           34 : 66  2016  \n",
       "2592                     8%           35 : 65  2016  \n",
       "2593                     2%           52 : 48  2016  \n",
       "2594                    15%           53 : 47  2016  \n",
       "2595                     3%           62 : 38  2016  \n",
       "2596                    43%           57 : 43  2016  \n",
       "2597                     2%           29 : 71  2016  \n",
       "2598                     3%           48 : 52  2016  \n",
       "2599                     2%           36 : 64  2016  \n",
       "2600                     3%               NaN  2016  \n",
       "2601                     8%           28 : 72  2016  \n",
       "2602                     4%           43 : 57  2016  \n",
       "\n",
       "[2603 rows x 14 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"world-university-rankings/timesData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2174, 82)\n",
      "(954, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>total_score</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Taiwan</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Turkey</th>\n",
       "      <th>country_Uganda</th>\n",
       "      <th>country_Ukraine</th>\n",
       "      <th>country_United Arab Emirates</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States of America</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2243</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>95.6</td>\n",
       "      <td>11074</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>94.3</td>\n",
       "      <td>15596</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>91.2</td>\n",
       "      <td>18812</td>\n",
       "      <td>11.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>91.2</td>\n",
       "      <td>19919</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  world_rank                        university_name  teaching international  \\\n",
       "1          2     California Institute of Technology      97.7          54.6   \n",
       "2          3  Massachusetts Institute of Technology      97.8          82.3   \n",
       "3          4                    Stanford University      98.3          29.5   \n",
       "5          6                University of Cambridge      90.5          77.7   \n",
       "6          6                   University of Oxford      88.2          77.2   \n",
       "\n",
       "   research  citations income total_score  num_students  student_staff_ratio  \\\n",
       "1      98.0       99.9   83.7        96.0          2243                  6.9   \n",
       "2      91.4       99.9   87.5        95.6         11074                  9.0   \n",
       "3      98.1       99.2   64.3        94.3         15596                  7.8   \n",
       "5      94.1       94.0   57.0        91.2         18812                 11.8   \n",
       "6      93.9       95.1   73.5        91.2         19919                 11.6   \n",
       "\n",
       "   ...   country_Taiwan  country_Thailand  country_Turkey  country_Uganda  \\\n",
       "1  ...                0                 0               0               0   \n",
       "2  ...                0                 0               0               0   \n",
       "3  ...                0                 0               0               0   \n",
       "5  ...                0                 0               0               0   \n",
       "6  ...                0                 0               0               0   \n",
       "\n",
       "   country_Ukraine  country_United Arab Emirates  country_United Kingdom  \\\n",
       "1                0                             0                       0   \n",
       "2                0                             0                       0   \n",
       "3                0                             0                       0   \n",
       "5                0                             0                       1   \n",
       "6                0                             0                       1   \n",
       "\n",
       "   country_United States of America  female  male  \n",
       "1                                 1      33    67  \n",
       "2                                 1      37    63  \n",
       "3                                 1      42    58  \n",
       "5                                 0      46    54  \n",
       "6                                 0      46    54  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToInt(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x\n",
    "df.dropna(axis=0,inplace=True,how='any') #borra nan\n",
    "df[\"total_score\"] = df[\"total_score\"].apply(lambda x: x.replace('-','unknown')) #rellena \n",
    "df = df[~(df == '-').any(axis=1)] #elimina filas con valores nulos\n",
    "#...\n",
    "nuevo_df  = pd.get_dummies(df, columns=[\"country\"]) #column to categorical\n",
    "#....\n",
    "nuevo_df['female'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[0].apply(convertToInt)\n",
    "nuevo_df['male'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[1].apply(convertToInt)\n",
    "nuevo_df['female_male_ratio'] =  np.where(nuevo_df['male'] == 0, 0, nuevo_df['female']/nuevo_df['male']) #si no hay (rellena 0) \n",
    "nuevo_df['num_students'] = nuevo_df['num_students'].apply(lambda x: int(str(x).replace(',','')))\n",
    "nuevo_df['international_students'] = nuevo_df['international_students'].apply(lambda x: int(str(x).replace('%','')))\n",
    "print(nuevo_df.shape)\n",
    "#...\n",
    "df_test = nuevo_df[nuevo_df[\"total_score\"]=='unknown']  #para predecir al final\n",
    "nuevo_df =  nuevo_df[nuevo_df[\"total_score\"]!='unknown'] #elimina unknown rank..\n",
    "print(nuevo_df.shape)\n",
    "nuevo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es verificar si existe una correlación entre la cantidad de alumnos y el ratio mujeres:hombres y utilizar esta \"linea de regresión\" para predecir el ratio de las universidades con ratio Nan para la cantidad de alumnos que estas tengan, siempre y cuando la correlación sea aceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954,)\n",
      "(954, 79)\n",
      "(1220, 79)\n",
      "(200, 79)\n"
     ]
    }
   ],
   "source": [
    "Y = nuevo_df['total_score'].values\n",
    "X = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "X_test = df_test.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "Y = Y.astype('float32')\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "#...\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#...\n",
    "X_val=X_train[:200]\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88d2b099e8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88db10f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "#...\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "res = y_train-linreg.predict(X_train_scaled)\n",
    "sns.distplot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24038632"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-78.07037     27.720373   -77.624115   -98.671394    17.195835\n",
      "  63.62563     70.10829     19.235205   -17.574589   -82.07824\n",
      "  28.642036    18.766823    -9.127907    28.642036   -67.17852\n",
      "   3.45477     28.874517    28.642036    54.887344    28.642036\n",
      "  28.642036    28.642036    74.37284     10.359038    28.642036\n",
      "  26.276642   -58.071644   -42.512497    28.642036   -71.36372\n",
      "  28.642036    28.642036    28.642036    28.642036    28.642036\n",
      "  37.959084   -11.721035    18.064728    28.642036    28.642036\n",
      "  28.642036    28.642036    10.358961    28.642036    28.642036\n",
      "  28.642036    28.642036    29.161198    -6.109456    28.642036\n",
      "  -0.83495295  28.642036    28.642036    28.642036    28.642036\n",
      "  28.642036     8.414542    28.642036   -15.835184    28.642036\n",
      "  28.642036    40.663017    28.642036    28.642036    -0.75687355\n",
      " -12.591621   -10.266298    23.153465    33.894848     6.4185367\n",
      "  28.642036   -59.527756    28.642036    28.642036    28.642036\n",
      "  20.148584   -28.87398     -8.432807    11.772389  ]\n",
      "[2.07207568e+08 1.30940100e+06 1.30695130e+09 3.85054297e+04\n",
      " 2.17631625e+06 4.12782000e+06 1.98516438e+06 3.26084400e+06\n",
      " 5.93142900e+06 2.60347156e+05 3.67056000e+06 8.65603000e+06\n",
      " 2.32332140e+07 7.82313216e+08 1.21481838e+06 2.24504125e+06\n",
      " 9.50716314e+09 3.97756672e+08 6.20890586e+04 3.63162920e+07\n",
      " 1.60778938e+06 5.87080742e+04 3.92161120e+07 1.95626825e+06\n",
      " 2.59946208e+08 1.27916734e+05 1.93878719e+05 8.52540688e+05\n",
      " 7.16779375e+04 2.49591600e+07 8.32750879e+03 4.58907539e+04\n",
      " 2.23373840e+07 2.53426740e+07 2.28010000e+07 2.30858700e+06\n",
      " 4.12803975e+06 1.33209256e+08 1.33474150e+07 5.30575625e+05\n",
      " 1.69488438e+04 1.16142980e+07 1.65879359e+05 6.56186865e+03\n",
      " 1.25656062e+06 8.99311797e+04 2.34456400e+07 5.40335600e+06\n",
      " 1.15927250e+05 1.33251062e+06 4.66004200e+07 8.04680100e+06\n",
      " 6.83202500e+05 1.00967650e+06 3.73594750e+06 6.17937720e+07\n",
      " 4.70152400e+07 1.70753360e+07 2.28699600e+06 3.45402625e+06\n",
      " 1.85876214e+10 4.45506750e+06 1.30173310e+07 5.86658080e+07\n",
      " 9.34773568e+08 1.16829773e+05 2.13691846e+03 7.30652240e+07\n",
      " 2.23219734e+05 2.18766925e+09 1.04857516e+05 3.02230800e+07\n",
      " 1.03397912e+06 9.16500312e+05 7.25322422e+04 5.04428500e+06\n",
      " 1.46285350e+07 4.61982375e+05 1.81155112e+06 1.34519561e+04\n",
      " 1.59100000e+06 3.91143875e+05 1.23833440e+07 4.51668500e+06\n",
      " 8.01802750e+05 1.00962560e+07 5.60848700e+06 5.46514727e+04\n",
      " 2.24046425e+06 2.00343984e+04 3.48797696e+08 1.14310352e+05\n",
      " 5.57145875e+05 6.16574720e+08 2.36540391e+04 3.74636275e+06\n",
      " 6.06085200e+07 1.48612320e+07 1.30830430e+05 2.04328094e+05\n",
      " 1.39063550e+07 1.83570944e+08 2.85517425e+06 6.62714100e+06\n",
      " 3.41754388e+10 2.89975860e+07 3.17671400e+06 2.55126075e+06\n",
      " 2.21980000e+06 5.65194961e+04 9.75649500e+06 5.31875200e+07\n",
      " 9.77102400e+06 1.88208000e+09 3.51923828e+02 4.10291120e+07\n",
      " 3.63204825e+06 2.51343200e+06 1.02524304e+08 1.03912850e+07\n",
      " 7.84061920e+07 3.08765560e+07 9.38037891e+04 3.79245719e+05\n",
      " 4.33933150e+06 3.50054300e+06 9.12241438e+05 1.81126860e+07\n",
      " 3.11200425e+06 2.38118391e+05 1.13325508e+05 3.50351150e+06\n",
      " 7.08808050e+06 1.82876992e+08 1.22152031e+05 2.50188600e+07\n",
      " 4.74716312e+05 2.54730219e+05 2.10269376e+09 1.65743600e+07\n",
      " 2.69374100e+07 6.37674304e+08 1.89893922e+05 8.08717350e+06\n",
      " 1.38651078e+05 1.26194856e+08 4.98688040e+07 5.61414562e+05\n",
      " 3.53668438e+04 2.62072925e+03 9.96126438e+05 5.21001094e+04\n",
      " 1.71856224e+08 1.30399928e+08 8.77807500e+06 4.39352600e+06\n",
      " 1.36530000e+05 6.15184440e+07 1.36579492e+03 2.56575456e+08\n",
      " 6.86073650e+06 1.92694920e+07 4.43558360e+07 7.12921500e+06\n",
      " 1.17559633e+01 1.51901500e+06 4.87292448e+08 1.94966352e+08\n",
      " 4.98426031e+05 1.77466086e+09 1.65576151e+10 1.61751175e+06\n",
      " 8.06539812e+05 3.29730912e+08 1.85769412e+06 2.80280120e+07\n",
      " 4.74991600e+07 2.07960380e+07 2.21380198e+09 1.08744610e+07\n",
      " 1.23138812e+06 1.25803738e+06 3.71690750e+05 1.51048944e+08\n",
      " 4.51777461e+04 2.82141620e+07 4.21118125e+05 3.72290550e+06\n",
      " 2.65674394e+09 1.73809688e+05 3.98087200e+06 3.15779700e+06\n",
      " 6.29851133e+04 4.35476800e+07 2.41292006e+09 1.27073875e+05\n",
      " 3.40912925e+06 1.59112672e+05 4.45786800e+07 1.64325880e+07\n",
      " 1.65108270e+07 2.15648832e+08 6.40804320e+07 7.90089450e+06\n",
      " 9.62668400e+06 2.17309040e+08 9.55431375e+05 1.03182852e+05\n",
      " 2.26576525e+06 6.22141000e+07 6.73425200e+07 4.01757275e+06\n",
      " 3.50349440e+08 2.40175672e+05 2.22988464e+08 3.06611168e+08\n",
      " 2.29664400e+07 6.52553477e+04 1.02090650e+07 4.72579375e+05\n",
      " 1.98264730e+09 1.12526720e+07 3.41068075e+06 2.06922420e+07\n",
      " 5.12279938e+05 6.56197360e+07 3.22700875e+06 4.02155930e+09\n",
      " 3.25228820e+07 5.85813938e+05 1.82781641e+05 3.68808730e+09\n",
      " 2.44650880e+07 3.66709525e+06 1.42069560e+07 6.85503850e+06\n",
      " 3.03142160e+07 9.65989600e+06 1.31068450e+06 1.91964625e+05\n",
      " 2.84952825e+06 1.75908920e+07 9.01915188e+05 2.32382880e+07\n",
      " 8.39801900e+06 4.18138086e+03 7.23400875e+05 1.09618475e+06\n",
      " 2.00092940e+07 1.27070266e+05 6.50770400e+06 2.00461280e+08\n",
      " 1.25168912e+06 2.83360775e+06 2.24843200e+06 1.71059800e+06\n",
      " 5.77490300e+06 1.45936090e+07 1.61745260e+07 4.25037578e+04\n",
      " 4.66774180e+04 1.75652750e+06 1.44260575e+06 1.80322660e+07\n",
      " 2.13656416e+08 5.79472500e+06 3.11940220e+07 6.92749688e+04\n",
      " 4.26374453e+04 5.67763072e+08 1.36694944e+08 3.96590600e+07\n",
      " 7.97224625e+05 3.89222250e+06 1.22171500e+05 8.00779297e+03\n",
      " 3.15253728e+08 5.85519555e+10 4.79261900e+06 3.67748531e+05\n",
      " 2.14732640e+08 7.74462625e+05 4.17464760e+07 5.11284050e+06\n",
      " 2.27701520e+07 3.23517200e+06 2.28755531e+05 4.83853280e+07\n",
      " 4.23684950e+06 1.61245725e+06 9.26026480e+07 1.63545475e+06\n",
      " 1.00843580e+07 1.29812200e+08 2.10055400e+07 1.73414420e+07\n",
      " 1.09062664e+08 2.22922422e+04 2.37650725e+06 2.30872253e+02\n",
      " 1.10595562e+05 9.71549800e+06 5.92951000e+05 1.19253490e+07\n",
      " 5.22640186e+03 1.47714062e+05 7.50817200e+06 8.54735200e+06\n",
      " 5.73381211e+04 9.37506094e+04 3.44134120e+07 9.93016016e+03\n",
      " 1.88870140e+07 3.61734120e+07 1.71484538e+06 7.20975600e+06\n",
      " 4.57735781e+05 1.63066736e+08 6.84940562e+05 3.76833750e+06\n",
      " 1.28452441e+04 1.54168420e+07 6.17231800e+07 3.19875825e+06\n",
      " 9.47975781e+04 1.38538575e+06 1.18763438e+05 2.04565264e+08\n",
      " 3.95477075e+06 3.05508160e+07 1.33907862e+06 3.85362675e+06\n",
      " 6.22097125e+05 3.16491775e+06 4.85405700e+06 1.76443800e+06\n",
      " 1.86535859e+05 1.65444875e+06 2.59825800e+06 7.61857700e+06\n",
      " 9.68610700e+06 8.33495375e+05 6.46820438e+05 1.79644700e+07\n",
      " 6.67855650e+06 5.50025960e+07 1.42228025e+06 1.51843962e+06\n",
      " 5.94852800e+07 1.35671812e+06 2.95843200e+06 1.15076950e+06\n",
      " 5.48245720e+07 1.88030075e+06 8.49870000e+07 3.70856960e+07\n",
      " 4.39267312e+05 3.16474863e+04 9.14699760e+07 1.90662835e+09\n",
      " 8.48331400e+06 9.00939264e+08 2.09218375e+06 1.03258900e+07\n",
      " 7.87660875e+05 3.14223260e+07 1.02654756e+04 3.13961780e+07\n",
      " 9.17175562e+05 1.51305808e+08 8.74169360e+07 4.38263562e+05\n",
      " 3.14974550e+06 5.32851040e+08 2.95002425e+06 9.41909600e+06\n",
      " 4.80549150e+06 2.01810240e+08 6.13046650e+06 4.50337229e+09\n",
      " 1.37830170e+09 9.91376800e+06 1.33227575e+06 8.85579844e+04\n",
      " 1.10612824e+08 9.38381900e+06 1.58956553e+04 2.00754860e+07\n",
      " 1.14638775e+06 4.27614850e+06 4.32875250e+05 7.46606850e+06\n",
      " 7.52372656e+04 7.24625879e+03 1.29116776e+08 7.17701688e+05\n",
      " 3.56701188e+05 1.43723990e+07 7.28075120e+07 2.65309648e+08\n",
      " 4.27231488e+08 5.85924440e+07 8.49461625e+05 5.69663232e+08\n",
      " 1.32652560e+07 2.58455160e+07 3.85871750e+06 4.17478938e+09\n",
      " 9.92097578e+04 8.97524562e+05 2.60703840e+07 1.32421248e+08\n",
      " 2.11907625e+06 8.02913680e+07 3.70441575e+06 2.96336719e+05\n",
      " 6.65434400e+07 1.57698930e+07 8.76316100e+06 1.91768734e+05\n",
      " 7.14237700e+06 1.69446188e+05 7.08230800e+06 4.12689640e+07\n",
      " 2.34789856e+08 1.75956000e+06 4.49883160e+07 1.05884400e+08\n",
      " 1.61948540e+07 1.77524153e+12 1.01859664e+08 9.66472600e+06\n",
      " 1.02319500e+07 2.43436120e+07 1.97210280e+07 7.66864160e+07\n",
      " 5.14312045e+11 1.46226309e+04 4.07812250e+05 1.30150410e+07\n",
      " 1.95885588e+06 2.22457325e+06 4.14722816e+09 4.84592906e+05\n",
      " 6.07855375e+05 1.42191091e+09 9.05035300e+06 1.49386212e+06\n",
      " 3.27542120e+07 4.09864250e+06 2.37326864e+08 1.71848700e+07\n",
      " 3.81338075e+06 3.63428680e+02 1.81592400e+07 5.10054844e+04\n",
      " 5.03182600e+07 1.47072768e+08 8.41881000e+06 1.85721160e+07\n",
      " 3.29718300e+07 1.42942225e+06 9.57354048e+08 5.45583240e+07\n",
      " 4.59355300e+06 1.29854144e+08 1.27993274e+03 1.02461488e+08\n",
      " 1.26604600e+07 1.37575872e+08 1.37051112e+06 2.25207700e+06\n",
      " 5.16491418e+09 1.51125975e+06 1.38725600e+06 3.23055020e+07\n",
      " 2.10072100e+06 6.71089250e+05 9.37451562e+05 1.20093297e+05\n",
      " 6.84847680e+07 6.45903938e+05 6.35454312e+05 4.73692950e+06\n",
      " 3.31183125e+04 5.84872250e+06 4.73950156e+04 2.20367075e+06\n",
      " 1.14642170e+07 2.60215400e+06 4.91507640e+07 1.29780600e+06\n",
      " 1.29194000e+07 4.22483125e+05 5.34451250e+06 2.48631350e+06\n",
      " 5.12774050e+06 1.13800136e+08 1.36019550e+06 5.85262400e+06\n",
      " 1.36836380e+07 6.92939250e+05 1.35562600e+06 4.73150500e+06\n",
      " 1.32508120e+07 7.85098800e+06 4.20627400e+07 4.14756525e+06\n",
      " 2.11561580e+07 8.82346300e+06 1.80253000e+07 1.00586348e+04\n",
      " 2.93371488e+08 1.82097680e+07 6.56656261e+10 5.79006560e+07\n",
      " 9.12630312e+05 2.49412992e+08 2.08834608e+08 6.09013888e+08\n",
      " 7.51973850e+06 2.25563920e+07 3.95480000e+06 3.15732050e+06\n",
      " 5.75482422e+03 9.23557360e+07 4.46956913e+10 3.83391880e+07\n",
      " 2.47990188e+05 3.50605688e+05 5.28221600e+06 2.96231689e+03\n",
      " 3.41068075e+06 1.53888340e+07 2.42133260e+07 2.53251875e+06\n",
      " 6.08310886e+10 1.05929630e+07 9.90823760e+07 6.27330048e+08\n",
      " 7.12293520e+07 7.33539750e+05 8.25940320e+07 7.18526250e+05\n",
      " 9.26987200e+07 1.02782825e+06 4.95337950e+06 1.17341125e+05\n",
      " 2.03040352e+08 2.22109094e+05 1.67756900e+06 3.31982344e+04\n",
      " 1.81709412e+03 1.94772038e+06 3.83692594e+05 3.63627300e+06\n",
      " 7.11154650e+06 1.17791168e+08 1.51872891e+04 5.42413688e+05\n",
      " 1.07731750e+06 7.93446000e+07 1.46513512e+06 9.93589300e+06\n",
      " 1.70137388e+06 7.18264064e+08 6.78113000e+06 1.97143162e+06\n",
      " 1.75428544e+08 5.31472800e+06 3.22357360e+07 1.05421362e+06\n",
      " 2.05861168e+08 2.63421875e+05 1.45957826e+13 1.76511642e+09\n",
      " 5.51446750e+06 4.37743600e+06 4.70730438e+05 4.55560000e+07\n",
      " 3.94014975e+06 9.65857856e+08 2.35844280e+07 8.46028125e+05\n",
      " 4.10547600e+06 2.12428656e+05 3.84709600e+06 1.81042380e+07\n",
      " 4.69032360e+07 1.18444438e+06 2.27438623e+03 9.68759840e+07\n",
      " 1.55604325e+06 3.15174375e+06 6.75932350e+06 6.84316953e+04\n",
      " 2.27508109e+05 1.20301445e+05 4.02174680e+07 2.63548926e+04\n",
      " 3.79920630e+10 4.10592360e+07 2.04719922e+05 1.08252450e+07\n",
      " 2.77908316e+10 9.84075250e+05 5.80620050e+06 6.43027266e+04\n",
      " 7.08584850e+06 1.86422400e+07 3.40689281e+05 6.09848704e+08\n",
      " 6.74720938e+05 2.73965250e+06 1.13580992e+09 8.42150812e+05\n",
      " 7.64637920e+07 7.62342976e+08 1.33687212e+06 1.34732260e+07\n",
      " 4.83645031e+05 1.26105211e+05 5.83365560e+07 3.93550912e+08\n",
      " 1.64194138e+06 2.00144880e+08 7.25535500e+05 1.69187696e+08\n",
      " 1.13311150e+06 1.91317080e+07 3.13338501e+03 2.79429740e+07\n",
      " 5.22104840e+07 7.82557312e+05 5.26908950e+06 1.43291490e+07\n",
      " 1.39063094e+05 1.41315200e+09 3.55769320e+07 9.03086700e+06\n",
      " 1.49933200e+07 7.69880550e+06 2.61288086e+03 1.42114109e+05\n",
      " 6.46596600e+06 1.09404210e+07 5.12185173e+01 1.10587950e+07\n",
      " 9.12073633e+03 1.23859552e+08 7.28057188e+05 2.13866425e+06\n",
      " 1.45818438e+05 2.57611425e+06 5.42363800e+06 7.88870800e+06\n",
      " 1.00744540e+07 4.79016650e+06 1.29160656e+08 7.79504922e+04\n",
      " 7.44166750e+06 2.50835719e+05 2.74920250e+05 2.85295400e+06\n",
      " 1.96342938e+05 1.51957650e+07 5.28987148e+04]\n"
     ]
    }
   ],
   "source": [
    "minies=[]\n",
    "for i in X_test_scaled:\n",
    "    minies.append(np.mean(i))\n",
    "nuevo_X=[]\n",
    "for i in range(len(X_test_scaled)):\n",
    "    nuevo_X.append( X_test_scaled[i] - minies[i] )\n",
    "\n",
    "nuevo_Y= y_train - np.mean(y_train)\n",
    "suma=0\n",
    "suma2=0\n",
    "for i in range(len(X_test_scaled)):\n",
    "    suma+=nuevo_X[i]*nuevo_Y[i]\n",
    "    suma2 += nuevo_X[i]**2\n",
    "a=0.0\n",
    "a=suma/suma2\n",
    "\n",
    "std=np.std(res)/np.sqrt(suma2)\n",
    "#print(std)\n",
    "#print(a)\n",
    "z_score=a/std\n",
    "print(z_score)\n",
    "\n",
    "y_gorro= linreg.predict(X_train_scaled)\n",
    "ssr=0\n",
    "sse=0\n",
    "for i in range(len(y_train)):\n",
    "    ssr+=(y_gorro-np.mean(y_train))**2\n",
    "    sse+=(y_gorro-y_train)**2\n",
    "f_score = ssr/(sse/(len(y_gorro)-2))\n",
    "print(f_score)\n",
    "#print(sst[:10])\n",
    "#print((nuevo_Y**2)[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "minfo_predictor = mutual_info_regression(X,Y)\n",
    "print(minfo_predictor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-62c9d16c92eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mselected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mnames_regressors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnuevo_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"world_rank\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"university_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mfss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-62c9d16c92eb>\u001b[0m in \u001b[0;36mfss\u001b[0;34m(x, y, names_x, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mresiduals_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = (range(0, p)),list()\n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = LR(fit_intercept=True, n_jobs=1)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print (\"selected = %s ...\"%names_x[best_candidate])\n",
    "        print (\"totalvars=%d, mse = %f\"%(len(indexes),best_new_score))\n",
    "    return selected\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "fss(X_train_scaled,y_train,names_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEMCAYAAADknlzeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl8VNXd+PHPmTt7JvtCErYALlCBBAm7IGBBUEBELVXUoo9FFJfaouJSBWtb2vIAUqs8WDXu4vKDUrdSIIggCkEChEXWsAVCFrLPZLbz+2MmYwIhCWESknDer9e8ZjJz7znnDuF7T84993uElBJFURSl9dBd7AYoiqIo50cFbkVRlFZGBW5FUZRWRgVuRVGUVkYFbkVRlFZGBW5FUZRWRgVu5bwIIaQQ4rJG7ttJCFEmhNCC3KahQogfg1lmUxBCrBVC3Hex26G0fipwt0JCiGwhhN0fBE8KIdKEELaL3a76SCmPSCltUkrPhZRz5slDSvmNlPLKC2/hWfUk+esq8z+yhRCzGrjvbCHEuxdQ93AhhNdfb6kQ4kchxD1nbBP4Hvz1ufzblgoh9gohXhZCJJyxT6gQYr7/WMqFEEeEEJ8IIfqfUW55teMuE0I80dhjUYJPBe7Wa7yU0gakAH2Apy5ye+okhNBf7DZcgAj/d3078JwQYkwz1ZvjrzcMeAx4TQhR1wlqqZQyFIgCbgbigS1VwVsIYQLWAL2Acf5yewAfAjecUVay/yRb9fhrMA9MuTAqcLdyUsqTwH/wBXDA9x9UCDHP35vKFUIsFkJYqn3+hBDihBAiRwhx3xk9txp/zgshpgoh1tdWtxDiRiHEViFEiRDiqBBidrXPqnqr/yOEOAKsqfaeXggx6IwenUMIke3ft78QYqMQosjfzpeFEEb/Z+v8VWzz7zfZ3zs9Vq3uHv7jKBJC7BRCTKj2WZoQ4h9CiM/9PdPvhRDdGvhdbwR2Aj39Zb3kP+4SIcQWIcRQ//tjgKeByf42bqtWTGchxAZ/3SuFEDENqFdKKb8ACoHeDdjeJaXcCUwG8oDf+T+6C+gATJRSZkkpPVLKcinlJ1LK2Q35DpSWQQXuVk4I0QEYC+yv9vZfgCvwBfPLgPbAc/7txwC/BX7u/+zaC6i+HLgbiABuBB4QQkw8Y5tr8fXqrq/+ppRyY1VvDogEvgM+8H/swdfDjAEGAdcBD/r3G+bfpqpHuLR6uUIIA/BvYCUQBzwMvHdGT/V2YI6/3v3AH+s7UOEzBLgK2Op/ezO+7zgKeB/4WAhhllJ+BfwJXw/YJqVMrlbUHcA9/rYZgZkNqFvnP/nEUPPfuU7+Ial/AUP9b/0c+I+UsryhZSgtkwrcrddyIUQpcBQ4BTwPvgAD/Bp4TEpZKKUsxRdEfunf7xfAm1LKnVLKCnwBrFGklGullDuklF4p5XZ8gffME8Fsf6/OXkdRi/CdBJ7xl7tFSvmdlNItpcwG/q+Wcs9lIGAD5kopnVLKNcBn+IJ1lf8npdwkpXQD71Htr5VzyMfX2/0nMEtKudrfznellAX+dv4vYALqG2t/U0q51/99fFRP3YlCiCLADiwDfiul3FrH9rXJwXdiAV/gP1n1gRAixf9XSYk4++LuD/7Pqh7Xo7QYrXnc8VI3UUq5SghxLb7eXgxQBMQCVnxjm1XbCqBqJkcikFGtnKONbYAQYgAwF9/QgRFf4Pr4jM3qLF8IcT8wHBgopfT637sCmA+k4jsWPbClgc1KBI5WleV3GN9fHVVOVntdgS/Q1yXGH+TPbPvvgPv8dUp8Y8b1DX2cT905UsoO/rHpucBIYGE95Z+pPb6TDkABELhYKaXMBCKEED/Hd1Kq7mopZYN790rzUj3uVk5K+TWQBszzv5WPr4d2lZQywv8I9w9JAJzAN85ZpeMZRZbjC5ZV4uuo/n1gBdBRShkOLMZ3kqjRxHPt7B8T/gNwk5SyuNpHrwJ7gMullGH4xovPLPdccoCOQojqv9udgOMN3L9B/G1/Et9fMJFSygiguFo7g5Z2U0pZ6a+rVy1DUXW1UQeMB77xv7UaGC2ECAlW25SLQwXutmEhMEoIkeLvab4GLBBCxAEIIdpX+1P3I+Ae/wU8K/6x72oygUlCCKv/guX/1FFvKFAopXT4p5Pd0dAGCyE6AkuBu6WUe2sptwQoE0J0Bx444/NcoOs5iv4e38nnCSGEQQgxHF/w+rChbWugUMCN7+KfXgjxHL4ed/U2Jp1xAmk0KaUT+F/O/vc6i/+4e+AbuorH99cLwNv4TtzLhBA9hRCaEMKM7y8bpRVRgbsNkFLm4ftP+Xv/W0/iu4j1nRCiBFiFf+xVSvklvjHldP82G/37VPqfFwBOfIHnLXxjwOfyIPCCf6z9OXwnhYa6Dl9Q+aTazJKd/s9m4jsJlOI7CS09Y9/ZwFv+sddfVP/AH+Am4Ltgmw+8gu/ksOc82tYQ/wG+BPbiG4pxUHNYqGrIqEAI8UOQ6nwD6CSEGH+OzycLIcrwDZmtwDc00ldKmQMgpXQAI4BdwOf4To4/Av3w/eVQ3TZRc9bP+Q7RKE1IqIUULm3+nlkWYKptHFdRlJZH9bgvQUKIm4UQRiFEJL6pg/9WQVtRWg8VuC9N9+Mbmz2Ab870mWPIiqK0YGqoRFEUpZVRPW5FUZRWRgVuRVGUVqZJ7pyMiYmRSUlJTVG0oihKm7Rly5Z8KWVsQ7ZtksCdlJRERkZG/RsqiqIoAAghDjd02wYNlQghIoQv2foeIcRuIcSgxjdPURRFuRAN7XG/BHwlpbzVnxfZWt8OiqIoStOoN3ALIcKAYcBUCNxS7GzaZimKoijn0pAed1d8N2u8KYRIxpde81GVjL1lcblcHDt2DIfDcbGborRyZrOZDh06YDAYLnZTlHNoSODWA1cDD0spvxdCvATM4qeERgAIIaYB0wA6deoU7HYq9Th27BihoaEkJSVRLQ+3opwXKSUFBQUcO3aMLl26XOzmKOfQkIuTx4BjUsrv/T9/gi+Q1yClXCKlTJVSpsbGNmhGixJEDoeD6OhoFbSVCyKEIDo6Wv3l1sLV2+OWUp70L4h6pZTyR3zpOHc1RWO+Pvo1Qgj0Qo9eV/Nh0BkwakaMOiMG7afXRs2ILjgpj1s9FbSVYFC/Ry1fQ2eVVC24agQO4lvsNOhmfj0Th+f8z/QGnQGzZsakN2HSTJg1M2a9GavBikVvwaq3YjVYsep9P4cYQgg1hhJqDMVmsAWew03hRJgiMGhqbO98FRUV8f777/Pggw8GrczZs2djs9mYOfPs9XQHDx7Mt99+G7S6FKU1aVDg9q9N1+SrZLxzwzu4PC7c0o3b68bldQWeXV4XLo/v2elx+h5e37PD46DSXUmlpzLw2u6x43A7yKvIw+62U+GuwO7yPXukp852hBhCiDBFBB5R5ihiLDHEWGKItcYGXsdZ4wgxqFWgwBe4X3nllaAG7rqooK1cylrUYsHdo7o3eR1SSuxuO2WuMsqcZZS6Sn3PzlJKnCWcdpymqLKIosoiTleepshRxKHiQ+TZ83B5XWeVF2YMI9GWSGJIIom2RBJCEmhva0/nsM50CuuEUTM2+TG1BLNmzeLAgQOkpKQwatQo4uLi+Oijj6isrOTmm29mzhzfYvITJ07k6NGjOBwOHn30UaZNmwbAV199xdNPP43H4yEmJobVq1cDsGvXLoYPH86RI0f4zW9+wyOPPAKAzWajrKyMtWvXMnv2bGJiYsjKyqJv3768++67CCH44osv+O1vf0tMTAxXX301Bw8e5LPPPrs4X5CiBFGLCtzNQQjhGzYxWImzxjV4PyklJc4S8u355NnzyKvI41TFKU6UnyCnLIcjpUf47sR3VLgrAvvohI7EkESSwpNICkuiS3gXLo+8nCsir2jSnvqcf+9kV05JUMv8WWIYz4+/6pyfz507l6ysLDIzM1m5ciWffPIJmzZtQkrJhAkTWLduHcOGDeONN94gKioKu91Ov379uOWWW/B6vfz6179m3bp1dOnShcLCwkC5e/bsIT09ndLSUq688koeeOCBs6apbd26lZ07d5KYmMiQIUPYsGEDqamp3H///YEyb7/99qB+H4pyMV1ygbuxhBCEm8IJN4XTLaJbrdtUBfdjpcfILsn2PYp9z1tyt2B3231lIegU1okrI6+kR3QProy8kp4xPYk0RzbnITWZlStXsnLlSvr06QNAWVkZ+/btY9iwYSxatIhly5YBcPToUfbt20deXh7Dhg0LTD+LiooKlHXjjTdiMpkwmUzExcWRm5tLhw4datTXv3//wHspKSlkZ2djs9no2rVroMzbb7+dJUuWNPmxK0pzUIE7iKoH96tiavZOvdJLbnkue0/vZXfhbn4s/JFdBbtYeXhlYJuksCT6xPWhT1wfUuJSSApr3JzsunrGzUFKyVNPPcX9999f4/21a9eyatUqNm7ciNVqZfjw4TgcDqSU5zxOk8kUeK1pGm732Sus1baNWiBEactU4G4mOqEjwZZAgi2BazteG3i/1FnKj4U/sj1/O1tzt5J+NJ1l+3090ihzFFfHXc2Q9kMYkjiEBFvCxWp+vUJDQyktLQXg+uuv5/e//z1TpkzBZrNx/PhxDAYDxcXFREZGYrVa2bNnD9999x0AgwYNYsaMGRw6dCgwVFK9190Y3bt35+DBg2RnZ5OUlMTSpWcuFK8orZcK3BdZqDGU1PhUUuNToaevt3qo5BBbc7ey9dRWvj/5PauOrAKgW3g3XxBvP4S+7fpi0kz1lN58oqOjGTJkCD179mTs2LHccccdDBrkSyJps9l49913GTNmDIsXL6Z3795ceeWVDBw4EIDY2FiWLFnCpEmT8Hq9xMXF8d///veC2mOxWHjllVcYM2YMMTEx9O/f/4KPUVFaiiZZczI1NVWqfNzBIaXkUPEh1h9fz4acDWSczMDpdWLRW7i2w7WMSRrDNR2u4eDeg/To0eNiN7dFKSsrw2azIaVkxowZXH755Tz22GMXu1mtwu7du9XvUzMTQmyRUjZo2rXqcbdwQgi6RnSla0RX7r7qbuxuOxknM1h7dC3/Pfxfvsr+ihBDCPN7zKfUWUqIIUTdSer32muv8dZbb+F0OunTp89ZY+6K0lqpHncr5va62XRyE//J/g/DjcOJS4pDJ3REmCKINEdi1psvdhOVVkr1uJuf6nFfIvQ6PYMTBzM4cTC7du2iY1hHiiuLOV15mkJHIVaDlShzFKHGUNULV5Q2RAXuNkIIEci/4va6KaosotBRyLHSY2g6jUhTJFHmKJWHRVHaABW42yC9Tk+MJYZoczTlrnIKHYXk2/MpcBQQYYogxhJzydyKryhtkQrcbZgQApvRhs1ow+lxkm/P9+VgcZwOBHCTvuVMKVQUpWHUwOclwqgZSbQlcnnE5URZoih2FrO/aD/HSo9R6a4MSh2DBw+ud5uFCxdSUVFR73YXKjs7m/fffz/wc0ZGRiBBVTAlJSWRn58f9HIVpS4qcF9iDJqBhJAEroi8ghhLDKXOUvYX7edE+Qnc3rNvJz8fDUm12pjA7fHUnYa3NmcG7tTUVBYtWnTe5ShKS6QC9yVKr9PTLqQdl0deTqQ5kkJ7IfuL9lPoKGx0ng+bzQb4cpIMHz6cW2+9le7duzNlyhSklCxatIicnBxGjBjBiBEjAF9CqkGDBnH11Vdz2223UVZWBvh6si+88ALXXHMNH3/8McOHD+fJJ5+kf//+XHHFFXzzzTeAL0APHTqUq6++mquvvjpw8pg1axbffPMNKSkpLFiwgLVr1zJu3DgACgsLmThxIr1792bgwIFs374d8C3ccO+99zJ8+HC6du1aI9BPnDiRvn37ctVVV6lkVcpFp8a426IvZ8HJHQ3aVA8kAu2kB6fXidfrxSF0GDUjmtB+2jC+F4yd2+Am1JZq9ZFHHmH+/Pmkp6cTExNDfn4+L774IqtWrSIkJIS//OUvzJ8/n+eeew7wrTa+fv16ABYvXozb7WbTpk188cUXzJkzh1WrVgVujzebzezbt4/bb7+djIwM5s6dy7x58wL5t9euXRto2/PPP0+fPn1Yvnw5a9as4e677yYzMxM4dxrZ2tLRRkdHN/j7UJRgUoFbAUATGmbNjEfn8a0q5Hag1+kxakYE55+hsLZUq9dcc02Nbb777jt27drFkCFDAHA6nYH8JgCTJ0+usf2kSZMA6Nu3L9nZ2QC4XC4eeughMjMz0TSNvXv31tu29evX8+mnnwIwcuRICgoKKC4uBs6dRra2dLQqcCsXiwrcbdF59IyrE/h+IXTSS749n3x7PprQSLQlEmoMPa+yGpKOVUrJqFGj+OCDD2otIySk5mITVWVWL2/BggW0a9eObdu24fV6MZvrv1u0tqGgqrSytbX7XOloFeViUWPcyll0QkecNY4u4V3QdBpHSo6QU5aDx3v+FwnPVD3968CBA9mwYQP79+8HoKKiokE95uqKi4tJSEhAp9PxzjvvBC5kVq/nTMOGDeO9994DfEMoMTExhIWF1VlHbeloFeViUYFbOSeL3kLX8K5EW6I57TjNweKDVLgubCrftGnTGDt2LCNGjCA2Npa0tDRuv/32wIXCPXv2nFd5Dz74IG+99RYDBw5k7969gV5679690ev1JCcns2DBghr7zJ49m4yMDHr37s2sWbN466236qxjzJgxuN1uevfuze9///tAOlpFuVhUkqk2oqmTApW7yjledhyXxxVY4b4xq/MorYNKMtX8gp5kSgiRDZQCHsDd0MKVtiPEEEK38G6crDhJvj0fu9tOh9AO6HXqMomiNLfz+V83QkqpbhG7hGk6jfa29oToQ8gpz+Fg8UE6hXZS6WMVpZm1qO7Stwfy8XglUoLEd/VfAkiQSLxe3/te6d/G/3nVz4H3/dtWf98b+Fzi8Vb/GTxS/vTaK/1tkP73weutuY+3Whmy2r7Vf/Y32/dcbTRKCNAJ4X/4X+tAr9Nh1PseBk2HSa/DqOkwG3TYzHpsJgM2k973MOsJM+uJtBrR6Zp/uCLCHIFRM3K09CiHig/R3taeMNO5L+4pihJcDQ3cElgphJDA/0kpz7p1TAgxDZgG0KlTp0Y15t60zThc3kbtG2xVAVYTAiFA0/0UbKteCyHQdCDwvS/8QVjg2wcIzICuGg8OnBC8VUHed+Jwe7w43V6cHi8uT8OuO2g6QXSIkdhQE7MGhXK0sAKDJjDqNUx6X/DXdKJJxqKtBitdw7tytPQoR0uPEuuJJdYSq8a9FaUZNDRwD5FS5ggh4oD/CiH2SCnXVd/AH8yXgO/iZGMa8+7/DEDiC3a+//++AOj7+aceKuAPnNV7sL5tRLXPfL3Zn/bzlSXQdP6ArKNmz7daYL6YAUhKidMfyO0uD+WVHsocbsoqqx4uiitc5Jc5ySutJK+sEq9XUlbpxu2RSH76+jWdwOQP5GaDhtWoYTFoQempGzQDSeFJ5JTlkFeRR6WnksSQRDSdVv/OiqI0WoMCt5Qyx/98SgixDOgPrKt7r/OXmhQV7CJbJSGqgq1GqNkADbj3Zffu3fRICKsR9CurHi4PZZVuTlc4A+Vb/EHcatQIMekxaI2bGaoTOtrb2mPWm8ktz8XtddMptJMK3orShOr93yqECBFChFa9BkYDWU3dMKVxqoJ+qNlAjM1E+wgLXWNt9EgIo0dCGJ2jQ4ixGRECCsudHCmsYPeJEvafKuNUqYNK1/nfZCOEIMYSQ4fQDthddg6XHL7gTIPBMnz4cNTUVKWtaUiPux2wzD90oAfel1J+1aStUpqEQdMRbtERbvEtX+aVEofLQ6nDTYndxcliByeLHZj0GuEWPeEWAxZjw69fh5vCEQiOlR3jUPEhOod2xqhv+pV23G43en2Lus6uKE2q3h63lPKglDLZ/7hKSvnH5miY0vR0QmA16mkXZubydqF0jw8jMcKCQRPklTrZd6qM/afKKKpwBmbK1CU7O5sBKQNY8PQCJlw7gQVLFjBw4MCzUrbOmjWLn/3sZ/Tu3ZuZM2cCkJeXxy233EK/fv3o168fGzZsAGDTpk0MHjyYPn36MHjwYH788UcA0tLSuO222xg/fjyjR48G4K9//Su9evUiOTmZWbNmBdr18ccfn5UOVlFaM9VNaYP+sukv7Ck8v1vHzyQluL2+GS5SSrqEXc7v+j5BVIgRfR3j4T/++CNvvvkmz85+llsm3cI/P/knP0v4GQvmLWD+/Pk89NBDLFu2jD179iCEoKioCIBHH32Uxx57jGuuuYYjR45w/fXXs3v3brp37866devQ6/WsWrWKp59+OpDZb+PGjWzfvp2oqCi+/PJLli9fzvfff4/VaqWwsDDQptrSwSpKa6YCt1IrIXxDKwbNN7dd0wlOljjILa0kwmKgXZgJo/7sC5CdO3dm4MCBfPbZZ2Tvy+aXY3/pSwvrgcGDBhMWFobZbOa+++7jxhtvDCxusGrVKnbt2hUop6SkhNLSUoqLi/nVr37Fvn37EELgcrkC24waNYqoqKjA/vfccw9WqxUg8D7Ung5WUVqzFhW49w4dinS6EJqG0DTQ6xF6ve9ngx4MBoTegDD4H3q979lkQhgNCKMRndGEMBoRJhM6ixlhMvuezWZ0Zgs6ixmd1YouJKTGQ5jNbWYO8pP9n2ySch0uDwVlTk5XOCm2u4ixGYkNNaNVm1pYleSpKmXrG++8weGSw+jQ0SW8C3pNz6ZNm1i9ejUffvghL7/8MmvWrMHr9bJx40YsFkuNOh9++GFGjBjBsmXLyM7OZvjw4WfVVVXfuf79aksHqyitWYsK3OETJiArnUiPG9xupNvz02uXG+l2I12uwLO3osL3s9OJrKwMPHtdLqTDAd7zuJlH09DZbGhhYb5HeBi6sHDf68hI9NFRaFHR6GOi0aKi0EdHo0VE+E4wlwizQaN9pIXYUBMnSxycKq2ksMJFfJiJSGvNi5ADBw5kxowZHM8+Tuekzuw+sZuvD35Nvyv6Uemo5IYbbmDgwIFcdtllAIwePZqXX36Zxx9/HIDMzExSUlIoLi6mffv2gG9c+1xGjx7NCy+8wB133BEYKqne61aUtqRFBe52/v+0wSJdLrwOB167Helw4LU7kPYKvHY73vJyvOXlePzP3vJyvCWleEpK8JQU4y0uwXUy1/dzURHU1lPTNPTt4jDEJ2CIj0efEI8hIRFDYgLGTp0wdOqEztj0syqam1Gvo1OUlZgQIznFDo6dtlNQ5sRZ+dMwRvWUrZWVlXill+lPTicsNIyH7noIh8OBlDKQcnXRokXMmDGD3r1743a7GTZsGIsXL+aJJ57gV7/6FfPnz2fkyJHnbNOYMWPIzMwkNTUVo9HIDTfcwJ/+9Kcm/y4U5WJQaV0bQHq9eEtKcBcU4C4owFNQgLugEHdeHu6TJ3CdOInr5EncJ08inc6fdtTpMCQmYkxKwti5M8akJExXXIG5R3e0OhL3N8bFSsMppaTYP5XQ6fESFWIkIdxSY/ikSpGjiONlxwkzhdHB1qHNDE21RSqta/MLelrXS53Q6dAiItAiIjB163bO7aSUeAoLceXk4Mw+jDM7O/Ao3roVb3l5YFtDx46Ye/TA/LMevufevdFHRjbH4QSVEIIIq5Ews4HcUgd5pZWUV3roFGXFYqw5jBRhjsAt3eSW53JSd5J4a7wK3orSCCpwB5EQAn10NProaCy9etX4TEqJ+1QelT/uwbFrN47dvkfpypWBbUyXX4a1X7/AQx8T09yH0Gg6nSAh3EKoSc/R03b255WREG4mOsRYIzhHm6NxeV0U2gsx6AzEWFrPMSpKS6ECdzMRQmBoF4ehXRy2YcMC73tKS3Hs3o39h61UbN5M0fJ/cfp93+K5xi5dCBk0ENt11xHSrx+iFYyX28wGLo/TOHbaTk6RnTKHmw6RlsDcbyEE8dZ43F5fz1sv9ESYIy5yqxWldVGB+yLTQkMJ6d+fkP79Yfr9SJcLx65dVGzeTPnmzRQtW87p9z9AFxqK7dprCf35dYRcMxTNFlJ/4ReJXtPROdpKQbmTE8UO9p0qo1OUlRCT79dNCEF7W3s8Xg855TmYNBMWg6WeUhVFqaICdwsjDAYsyclYkpOJvu8+vA4H5d9upHT1KsrWpFPy2WcIg4GQwYMJnzSJ0BHDW2RPXAhBjM1EiFHjSKGdg/nldIqyEG7xtVUndHQI7cDBooMcLT1K14iuahk0RWkg9T+lhdOZzYSOHEHoyBFIjwd7Zialq1ZT8uWXlD36KFpUFOETJyLHjrnYTa2VxainW2wI2QUVHCmoIDFCEm3z3RCj1+npGNqRQyWHOF52nE6hndTFSkVpgMYlYVYuCqFpWPv2pd2TT3DZ6lV0XPJ/WPv2pfDtt3GfOkXlwYO4T59Gns+NR01o8eLFvP322+g1Hes++5iKonyOF9nJLfHN4QawGCwkhCRQ5izjVMUp0tLSyMnJCZRx33331bgVXlEU1eNutYSmYRs2DNuwYbjz8thz6BDS7cZ1/Dju3Fz0MTFoUVEI3cU7N0+fPj3w+u233+KvvXoSmZhIbokDl8dL+wgLQggizZFUuCvIt+fz+huv07NnTxITEwH45z//ebGarygtlupxtwH62Fi00FBMl1+OsXMSwmjCdfIklT/uxZWXh/Sc/+IIjfH222/Tu3dvkpOTueuuu5g9ezbz5s3jk08+ISMjg7vuvJPxIwdj03v50x9fJOXqVHr27Mm0adOIt8aT/nk6W37Ywh1T7iAlJQW73V5jIYQPPviAXr160bNnT5588qd8LDabjWeeeYbk5GQGDhxIbm4u4Evn2rNnT5KTkxlWbSaPorR26s7JNqL6nW4n//QnHDt3Ip0upMfjGzc2+BNy0bgxZFOP7sQ//fQ5P9+5cyeTJk1iw4YNxMTEUFhYyKJFi7DZbMycOZPhw4czb948UlN9N4btO3wCu2bBZtLz3GMPMHnyL7j+huu55tpreOoPTzHh2gloOi2wX2JiIgMHDmTLli1ERkYyevRoHnnkESZOnIgQghUrVjB+/HieeOIJwsLCePbZZ+nVqxdfffUV7du3p6ioiIgINe2wodSdk83vfO6cVD3uNkroNHRmMzqLBTTNF8Qr7L4EXU1Q35o1a7j11luJ8d/K3b75AAAgAElEQVQ0VF+Cp+0Z33LPzaO5fmh/Vq1eTVZWFkbNiEkz4fQ4OVF+guqdis2bNzN8+HBiY2PR6/VMmTKFdet8y54ajcZAetjqqVuHDBnC1KlTee211/A0018ditIc1Bh3G1Rbz9hrt+M6cQJvRQU6sxl9QgJaSPDmgteVVvVMDoeDBx98kIyMDMwRcTz3/PPkFZUhpUQTGpHmSIori7EZbDXKPxeDwRCou3rq1sWLF/P999/z+eefk5KSQmZmJtHR0RdwlIrSMqge9yVCZ7Fg7NIFQ4cOSLcH56FDOI8dw1ttYYILcd111/HRRx9RUFAAUGMFGoDQ0FBKS0sBX+AGiImJwSJcpH/1b+wuD7kllYSGhqJ36rEYLDV63QMGDODrr78mPz8fj8fDBx98wLXXXltnmw4cOMCAAQN44YUXiImJ4ejRo0E5VkW52FSP+xIihEAfEYEWGoo7Px93fj6ekhIMcXFo0dEXNIf6qquu4plnnuHaa69F0zT69OlDUlJS4POpU6cyffp0LBYLGzdu5Ne//jW9evUiKSmJQQP6YzFonCp1MGnyFB544AHMFjNpn6VR6alESklCQgJ//vOfGTFiBFJKbrjhBm666aY62/T444+zb98+pJRcd911JCcnN/r4FKUlURcn24jGXEzyOp24T5zAU1qKzmrF0KHDRcsfLqXkSGEFxXYXHaOsRFqNnHacJqcsh/iQeKItaoijOamLk82vSS5OCiE0IcRWIcRnjW+a0pLojEYMnTphaN8e6XDg3L/fdwNPE5zM6yOEoGOkL5/JsUI7JQ4XEaYIQo2h5Fbk4nA7mr1NitJSnc8Y96PA7qZqiHJxCCHQR0ZivOwyhNmM6/hxXEePIi/C2ow6nSAp2orZoONIQQWVbi8JtgR0QsfxsuN4Zcu4I1RRLrYGBW4hRAfgRkDdxtZG6YxG38XLdu3wlJZSuX8/Hv/FxOak6XQkxYSg0wkOF1SgQyMxJBGH20FeRV6zt0dRWqKG9rgXAk8AqsvThgkh0MfGYuraFaFpOA8fxnXqVLMPnRg0HZ2jrDjdXo4W2gk1hhJhjiDfnk+Fq6JZ26IoLVG9gVsIMQ44JaXcUs9204QQGUKIjLw81TNqzXQWC8Zu3dAiInCfOuUbOmnmG1hCTHoSws2UOFzklVYSb43HoBk4VnYMj1fdTKNc2hrS4x4CTBBCZAMfAiOFEO+euZGUcomUMlVKmRobGxvkZirNTeh0GNq3xxAfj6eklMqDB/FWVjZrG6JtRiIsRnJLHFQ4vbS3tcflcZFnVx0D5dJWb+CWUj4lpewgpUwCfgmskVLe2eQtUy46IQT6mBiMSZ3B7cZ58GCd496DBw8Oev3tIy2YDBpHCyswCDOR5kgK7AXY3fag1qUorYm6c1Kpl2azYezWDWEw4Dx8GHdeXq3j3t9++23w69YJOkdZkRIOF1YQa4lDr9OTU5ZzUaYtKkpLcF6BW0q5Vko5rqkao7RcVbNOtPBwXLm5uE+cOCtw2my+3CJr165l+PDh3HrrrXTv3p0pU6YEtt28eTODBw8mOTmZ/v37U1paisPh4J577qFXr1706dOH9PR0ANLS0pg4cSK3TprIDUNSeGPJq/zhz/O4beRtTPr5JA7kHAB8t7aPGTOGvn37MnToUPbs2dOM34yiND91y3sb9M1He8k/WhbUMmM62hj6iyswdOiAMBhw5+cjPR4M7dvXuljD1q1b2blzJ4mJiQwZMoQNGzbQv39/Jk+ezNKlS+nXrx8lJSVYLBZeeuklAHbs2MGePXsYPXo0e/fuBSArK4utW7ficDjodtllPDLreb7+NoOZjz/A62mvM2fWHKZNm8bixYu5/PLL+f7773nwwQdZs2ZNUI9fUVoSFbiV8yKEwBAfj9D0uHJPIj0ejB07IjStxnb9+/enQ4cOAKSkpJCdnU14eDgJCQn069cPgLCwMADWr1/Pww8/DED37t3p3LlzIHCPGDGC0NBQQkNDiQgPZ8wN48gpspOa3J+NP2zgQO4Bvv32W2677bZA3ZXNfBFVUZqbCtxt0NBfXNHkdehjY0Cv4TqegzM7G2PnzjU+N5lMgddVqVbPlfq1rrHq6uXodDq6xIVz2gullRIDBkoqSwiPCCczMzMIR6UorYO6OKk0mj4yEmOnjngdDioPHqp3++7du5OTk8PmzZsBKC0txe12M2zYMN577z0A9u7dy5EjR7jyyitrLcNk0EgIN1Pp8oI0EBMZQ0LHBJYuXQr4TgLbtm0L0hEqSsukArdyQbSwMIxJSeB2g5R1zvU2Go0sXbqUhx9+mOTkZEaNGhVYVMHj8dCrVy8mT55MWlpajZ72maJCjJgNGhWVXmLM8cx9dS6L/7mY5ORkrrrqKv71r381wZEqSsuh0rq2ERc7DafX4cDpXzLM2KULujoCbzC4PF725pZi0muEWEspdBTSJbwLVoO1Seu9VFzs36dLkVpzUml2OrPZ1/OW4Dx0qMnvsjRoOtpHWKhwuhHecPQ6/VnrVCpKW6UCtxI0OrMZY5ckkBJndjZep7NJ64uw+m6JzytxEWmKxeF2UFRZ1KR1KkpLoAK3ElSBnrfX6+t5N3HwTowwo9cEp0sNWPQWcityVRIqpc1TgVsJOp3F0mzBW6/p6BBpodLtwUAUHq9HJaFS2jwVuJUmEQjeHq9v2CRIq8nXJtRsINJqpKhMEGoMp9BeSKVb3YSjtF0qcCtNxhe8/ZkFs7ObdDm0hHAzmk5Q6QhFCMHJipPqQqXSZqnArTQpndWKoXNnpNOJ8/DhJluQQa/pSIgwY3dKQvRRlDnLKHMFN1+LorQUKnArTU4LCcHYsSNeux3XsWNIb9OsgJf5/QZ+3JZBaZkZo2bkZPnJBi0wPHXqVD755JPG1ZmZyRdffNGofRWlsVTgVpqFFhaGITERT2kprpymyaX99ddfc2DnD0hA80bi9DgpsBcEvZ7qVOBWLgaVZKoNSk9bwqnDB4NaZlznroyYOq3ObbKzsxk7dizXXHMN3377Le3bt+df//oXY8eOZd68eaSmppKXm8vAAQPYv2UL7331FcuXL8fj8ZCVlcXvfvc7nE4n77zzDiaTiS+++IKoqKha61q0aBGLFy9Gr9fzs5/9jLlz57J48WI0TePdd99j5vN/5t+fvsHQUdcw4+4ZGDQDNpuNsrIypJQ8/PDDrFmzhi5dutQ4iWzZsoXf/va3lJWVERMTQ1paGgkJCQwfPpwBAwaQnp5OUVERr7/+OgMGDOC5557Dbrezfv16nnrqKeLj43n00UcBXybFdevWERoaGrx/CEVB9biVINu3bx8zZsxg586dRERE8Omnn9b4XB8Tg9DpcOfn4yktJSsri/fff59NmzbxzDPPYLVa2bp1K4MGDeLtt98+Zz1z585l69atbN++ncWLF5OUlMT06dN57LHH2L4tk8HXDMXrMSCRnKo4VWPfZcuW8eOPP7Jjxw5ee+21wMo9LpeLhx9+mE8++YQtW7Zw77338swzzwT2c7vdbNq0iYULFzJnzhyMRiMvvPACkydPJjMzk8mTJzNv3jz+8Y9/kJmZyTfffIPFYgnit6soPqrH3QbV1zNuSl26dCElJQWAvn37ku3PX1JFCAGahhYWhqe4mGuHDAnk2w4PD2f8+PEA9OrVi+3bt5+znt69ezNlyhQmTpzIxIkTa3ymE4L2ERa8XoFBWCmqLCLK8lPPfd26ddx+++1omkZiYiIjR44E4McffyQrK4tRo0YB4PF4SEhICOw3adKkcx5XlSFDhvDb3/6WKVOmMGnSpEBOckUJJtXjVoKqtjzcer0er/+CpMPhAPCtpGMyYXC58JSXA75821X763Q63HVMH/z888+ZMWMGW7ZsoW/fvmdtG2LSYzUbcTgM6ITGybKTOKvdCHSuvOBXXXUVmZmZZGZmsmPHDlauXHnWsVUdV21mzZrFP//5T+x2OwMHDlTLqClNQgVupcklJSWxZcsWgMDsDaHToY+KAp0O15Ej55WUyuv1cvToUUaMGMFf//pXioqKKCsrIzQ0lNJqq9D3uKIbu3dsR+cN598r/o3LfxPQsGHD+PDDD/F4PJw4cSKwxuWVV15JXl4eGzduBHxDJzt37qyzLWfWeeDAAXr16sWTTz5JamqqCtxKk1CBW2lyM2fO5NVXX2Xw4MHk5+cH3heahua/cOc8fKTB5Xk8Hu68887A4sKPPfYYERERjB8/nmXLlpGSksI333zD/dOmsW3zRm4ZNY6sH3ZiDbHilV5uvvlmLr/8cnr16sUDDzzAtddeC/jyhX/yySc8+eSTJCcnk5KSUu/K9SNGjGDXrl2kpKSwdOlSFi5cSM+ePUlOTsZisTB27NhGfGOKUjeVj7uNaM35kz3l5Tizs9FZrRg7d6518eHGklJyMK+cSm85Up9PfEg80ZbooJXfVrXm36fWKqj5uIUQZiHEJiHENiHETiHEnAtvoqL8RAsJwZCYiLe8HNeJ4ObUFkKQGGHG4zahF2by7Hkqe6DS6jWka1MJjJRSJgMpwBghxMCmbZZyqdFHRqKPjcVz+jSegp9umpkxYwYpKSk1Hm+++eZ5lW0x6okKMeGsDFPZA5U2od7pgNLX/alK+mDwP1T2HiXo9HFxyMpKXCdPIoxGtLAw/vGPfwSl7HZhJortTnSEUOgoJMochVEzBqVsRWluDRpMFEJoQohM4BTwXynl97VsM00IkSGEyMjLUz0a5fwJITB06IDOYsF57Bhe/9TBYNBrOtqFmXFWhoKE3IrcoJWtKM2tQYFbSumRUqYAHYD+QoietWyzREqZKqVMjY2NDXY7lUuE0OkwdOqE0OlwHj4S1FSwUSFGLHojeEIpqSyhwlURtLIVpTmd1+V7KWURsBYY0yStURRAZzBg7NQJ6XbhPHYsaBcrfRcqLbhdNoTQVM5updVqyKySWCFEhP+1Bfg5oO4qUJqUzmr1zTQpK8N98mTQyg0x6Ym0mvC6QrG77JQ6S+vfSVFamIb0uBOAdCHEdmAzvjHuz5q2WUpbsHDhQioqzn84wmazAf6ZJlHRuAsKcBc1bPX2tLQ0cnJy6twmPtyM8NgQGMityMUrvSxfvpxdu3bVW35eXh4DBgygT58+fPPNN3z88cf06NGDESNGNKh951JUVMQrr7wS+DknJ4dbb731gspU2q56A7eUcruUso+UsreUsqeU8oXmaJjS+jU2cFenj2+HLiQE1/HjeCvs9W7fkMBt0HTEhZnxOMNwepycdpxucOBevXo13bt3Z+vWrQwdOpTXX3+dV155JXDbfF3qyr1yZuBOTExs9OIOStunsgO2QUX/PoAzpzyoZRoTQ4gY3+2cn5eXl/OLX/yCY8eO4fF4uO2228jJyWHEiBHExMSQnp4eyIcNvpwln332GWlpaRw6dIg77rgDt9vNmDE1L5/M+9//5aOlS3GUljLh5z/nxYULOXz8eK15vz///HMyMjKYMmUKFouFjRs31ppWddasWaxYsQIPOgYPH8joCdexYsUKvv76a1588UU+/fRT1qxZw5IlS3A6nVx22WW888477N27lyeeeAK73U5KSgo333wz69ev59ChQ0yYMIG//e1vZ9WVlpbG559/jsPhoLy8nBUrVnDTTTdx+vRpXC4XL774IjfddBOzZs3iwIEDpKSkMGrUKGbMmMG4cePIysrC4XDwwAMPkJGRgV6vZ/78+Rfcw1daNxW4laD46quvSExM5PPPPweguLiYN998k/T0dGJiYurc99FHH+WBBx7g7rvvrjFve+XKlezbt49Nmzfjqahg/A03svrTT+nWvz/79u3jgw8+4LXXXuMXv/gFn376KXfeeScvv/xyYNGG2hQWFrJs2TL27NlDqcPNjuzDRMRWMuqGUdw28bbA8ERERAS//vWvAXj22Wd5/fXXefjhh3nhhRfIyMjg5ZdfBiA9Pb3O+gA2btzI9u3biYqKwu12s2zZMsLCwsjPz2fgwIFMmDCBuXPnkpWVRWZmJkCNtLFV38mOHTvYs2cPo0ePZu/evZjN5jq/V6XtUoG7DaqrZ9xUevXqxcyZM3nyyScZN24cQ4cObfC+GzZsCCy4cNddd/Hkk08CvsC9cuVK+vTpA0BZSQn79u6lc9eu9eb9PpewsDDMZjP33XcfN954I1cNHIHbW0SlpxK396ehjKysLJ599tlA5sHrr7++wcdzplGjRgVW8pFS8vTTT7Nu3Tp0Oh3Hjx8nN7fuOeXr16/n4YcfBqB79+507tyZvXv30rt370a3SWndVOBWguKKK65gy5YtfPHFFzz11FOMHj36rG2q58B2nHFzzbnyYz/11FPcf//9gfdcJ05wYPt2TPqffnU1TcNur3/8G0Cv17Np0yZWr17Nhx9+yKK//52/v/sJSCiuLA5sN3XqVJYvX05ycjJpaWmsXbu2QeXXJiQkJPD6vffeIy8vjy1btmAwGEhKSjrruziTmrKonEmldVWCIicnB6vVyp133snMmTP54YcfzspV3a5dO3bv3o3X62XZsmWB94cMGcKHH34I+AJbleuvv5433ngjMC5+/PhxCoVAWCxIt7vWOyvPrPNMZWVlFBcXc8MNN7Bw4UK2b9tGdIgVa0gEeafzcLh9ZZaWlpKQkIDL5arRpgtVXFxMXFwcBoOB9PR0Dh8+XG+7hw0bFmjD3r17OXLkCFdeeWXQ2qS0PqrHrQTFjh07ePzxx9HpdBgMBl599VU2btzI2LFjSUhIID09nblz5zJu3Dg6duxIz549AwH5pZde4o477uCll17illtuCZQ5evRodu/ezaBBgwDfNMF3330Xg385MeeRI5i61RwWmjp1KtOnTz/nxcnS0lJuuukmHA4HUkoWLFhAXKiJGyb8kuefmMEH//yAFctW8Ic//IEBAwbQuXNnevXqVefJ4HxMmTKF8ePHk5qaSkpKCt27dwcgOjqaIUOG0LNnT8aOHcuMGTMC+zz44INMnz6dXr16odfrSUtLq7HSkHLpUfm424hLLX+yp7wc56FstLBQDB071jrUcj4KyirJKctDpy+mc1hnbEZbkFraOl1qv08tQVDzcStKS6SFhGCIb4enpARPtVV1GisqxIhJhIHUq1vhlRZPDZUorZYWHY3XbseVm4uwWNBsNXvJN998M4cOHarx3l/+8pdaZ4gIIUgMt3LodBiVopCiyiIizZENbst//vOfwGyYKl26dKkxlq8owaICt9JqCSF8+UwcDlxHjyEu64bOYAh8fr5B02bWE2YMo8xbRm7FKcKMYWg6rUH7Xn/99Rc0ZVBRzocaKlFaNaFpGDt1AunFdeQo0uu9oPISws1IVzger5sCR0H9OyjKRaACt9Lq6UwmDO3b47VX4K7nZpb6GPUaMSFhSI+FfHs+Lo8rSK1UlOBRgVtpE7Tw8EAmQU9xcf071CE21IQmI5AScitOBamFihI8KnArbYY+vh06i8WXSbCystHlaDpBQpgNr9tGcWURdnfD7spUlOaiArcSNIMHD653m2Ckej0XodNh6NgRhGDfxo289+67gc8yMjJ45JFHGlxWuMWARRcB6DhZfu7pgUlJSeSf53TEC81T3hgNSXertB4qcCtB8+2339a7TWOClsfjafC2OqMRQ4cOZB86xHtpaYH3U1NTWbRoUYPLEULQPsKK1xVGhasiqCvlNOXJ61xU4G5b1HTANujLL7/kZBCX+wKIj49n7NixdW5TlW977dq1zJ49m5iYGLKysujbty/vvvsuf//738/K0b1y5Uqef/55Kisr6datG2+++SY2m42kpCTuvfdeVq5cyUMPPcTixYsZMGAA6enpFBUV8frrrzN06FCys7O56667KC/35R9/+eWXGTx4MM+9/DJ79u4luVcvpt57L3369GHevHl89tlnFBYWcu+993Lw4EGsVitLliyhd+/ezJ49myNHjnDw4EGOHDnCb37zGybddR9F7jIm3TyJ07mncTgcPProo0ybNq3e7+zMHOW///3vyc3NDUqe8r/97W989NFHVFZWcvPNNzNnzhyys7MbnKd8zpw5rFixAr1ez+jRo5k3b14jfzOUi0H1uJUmsXXrVhYuXMiuXbs4ePAgGzZs4JFHHiExMZH09HTS09PJz8/nxRdfZNWqVfzwww+kpqYyf/78QBlms5n169fzy1/+EvCtILNp0yYWLlzInDlzAIiLi+O///0vP/zwA0uXLg0Mh8ydN48h/frx3Ycf8uj06TXa9vzzz9OnTx+2b9/On/70J+6+++7AZ3v27OE///kPmzZtYs6cOURbNIQ7ghdeeoGV61eSkZHBokWLKCiof6pgVY7ybdu2kZWVxZgxY876DupSlad88+bNxMfHB94P5CnftInMzEy2bNnCunXrANi3bx8zZsxg586dRERE8Omnn3LrrbeSmprKe++9R2ZmJna7nWXLlrFz5062b9/Os88+W++xKC2L6nG3QfX1jJtD//796dChAwApKSlkZ2dzzTXX1Njmu+++Y9euXQwZMgQAp9MZSCgFMHny5BrbT5o0CaiZf9vlcvHQQw+RmZmJpmns3bsX8A116CwWhKbhPHoUWW24Zf369YH83yNHjqSgoIBi/0yUG2+8EZPJhMlkIi4ujoL8PNqFx/KP+R+y5suVGDUjR48eZd++fURHR9f5HVxIjnI4jzzlZWXs27ePTp06NShP+Zk5yceNG3de7VIuPhW4lSZRPXudpmm1rrcopWTUqFF88MEHtZZRPY919TKrl7dgwQLatWvHtm3b8Hq9NVeFEQJDx444D2XjrnYBsbYLjVVJqmpr946Mb/l+3Sbe/eJdEqPac8e42+vNoQ215yh/7rnnzlk3ND5POfhWzTmz/bXlKT8zJ/nLL7/MmjVr6j0epeVQQyVKs6qed3rgwIFs2LCB/fv3A1BRURHoMTdUcXExCQkJ6HQ63nnnncCFzKp6tJAQDO3a4a2oQDqdQM381mvXriUmJoawsLBz1lFSUkJcTDRmUwxbdmTw3XffNahtteUoP/M7gODkKT91qu755tXrPDMnedVyaUrrUW+PWwjREXgbiAe8wBIp5UtN3TClbZo2bVqNHN1paWncfvvtVPrnXb/44otcccUVDS7vwQcf5JZbbuHjjz9mxIgRgV5679690ev1JCcn86tf/Ypeie3xVlbiqahg9uzZ3HPPPfTu3Rur1cpbb71VZx1jxoxh8eLF3DZyHJ26tSc5NaVB2QNry1Fe23cQrDzlmnbuvCrV85R/+eWXZ+UkV1qXevNxCyESgAQp5Q9CiFBgCzBRSrnrXPuofNzNT+VPrpv0eKjcfwCQmLp1Q+jPf5TQ5fGyN+8k6E/TIbQD4abw4De0hVC/T80vqPm4pZQnpJQ/+F+XAruB9hfWREVpXr5kVB2RbjfOY8calW/boOmIC4lCeg2cKDuJx9vw+eWKEkzn1e0QQiQBfYDvm6IxitKUdBYLhoQEXDk5uPPyMMTFnXcZMTYThfYo3DKXPHse8SHxFBQUcN1115217erVq+udeaIojdHgwC2EsAGfAr+RUpbU8vk0YBpAp06dgtZARQkmLTISb0UF7lOn0FmtZy2+UB8hBB3CIzhUVEqBvYBIUyTR0dHqAp/SrBo0q0QIYcAXtN+TUv6/2raRUi6RUqZKKVNjY2OD2UZFCRohBIaEBHQmE66jR/H6Z5qcjxCTnnBDDCDIKTuhljlTml29gVv4JpK+DuyWUs6vb3tFaemEpmHo1AmkxHW0cYsvJISHgCecCnd5UPOYKEpDNKTHPQS4CxgphMj0P25o4nYpSpP6afEFO+5G5HXRazribTFIqSen7CReeWEr7yjK+ah3jFtKuR44+/YtRWnltPBw9HY77vx8hNWKPiLivPaPshopqIjCJU9xqiKP+JB2TdRSRalJ3TmpBM2iRYvo0aMHU6ZMaZLyZ8+eHfQsdvp27dCFhOA6noO3ltvDAYYPH05t9yUIIegYEYX0WCiw5+Nw138bfG2WL1/Orl0/3Rbx3HPPsWrVqkaVpVwaVOBWguaVV17hiy++qHF7dksnhMDYoQNC052VjKohLAaNKHM7pNRxtPT4OS9U1pVT/MzA/cILL/Dzn//8vNqhXFpUkqk2aO/eP1BatjuoZYbaenDFFb8/5+fTp0/n4MGDTJgwgV/+8pccOHCAHTt24Ha7mT17NjfddBNpaWksX74cj8dDVlYWv/vd73A6nbzzzjuYTCa++OILoqKieO2111iyZAlOp5PLLruMd955B6vVWqO+AwcOMGPGDPLy8rBarbz22mt079691rZNnToVi8XCnj17OHz4MG+++SZvvfUWGzduZMCAAaSlpWHo2Inp997DD7t34/B4uPXWWwOpY6urLX94fFgIJXmROD0F5NsLibX65m6fmVO8tLT0rOPKzMxkxYoVfP3117z44ot8+umn/OEPf2DcuHHceuutrF69mpkzZ+J2u+nXrx+vvvpqjURSyqVJ9biVoFi8eHEgz3R5eTkjR45k8+bNpKen8/jjjwcWOsjKyuL9999n06ZNPPPMM1itVrZu3cqgQYN4++23AV/61s2bN7Nt2zZ69OjB66+/flZ906ZN4+9//ztbtmxh3rx5PPjgg3W27/Tp06xZs4YFCxYwfvx4HnvsMXbu3MmOHTt8KWFDrPzxj39k/fvvs2XVKr7++mu2b99eo4xz5Q/XCUGn8Bik18ypilycnp+mGFbPKV7bcQ0ePJgJEybwt7/9jczMTLp16xbY1+FwMHXqVJYuXRo4CVblO1EubarH3QbV1TNuDitXrmTFihWB8WiHw8GRI0cAGDFiBKGhoYSGhhIeHs748eMBX+7qqkCZlZXFs88+S1FREWVlZVx//fU1yi8rK+Pbb7/ltttuC7z3/9t78/g6r/rO/33Os91V0pVsybtkO05CEsdxIQl0UgoFQsqwNDDpMGV+P2jD+ho6LNOFLblkeBQAACAASURBVJR5sRQK4TWEwo+GgaSAKRBSIFPaXyjphMBrICxJKeCQeJMj2ZZlbVdXuvc+2znzx3nuleRIlmzL2vy8Xz4+53nuo3vPeZbP8z3fs/nzLA78kpe8BCEEu3fvpquri927dwNw5ZVX0tvbyzXXXMO9//zP3PnpTxP5PgMjI+zfv5+rr766+R1nmj8859mU3E7Goj76KsfZ0doNzJxTfL5ync7jjz/O9u3bm5NuvfrVr+ZTn/oUb33rW8/4dylrn1S4UxYdrTX33nsvl1122Yz9Dz/88IxqvpSyuS2lbM6x/ZrXvIZvfvOb7Nmzh7vvvpsHH3xwxvcopWhrazur0YrTf+f0PERRxJEjR7j99tv58cMPkx8d5bV/8idUKzP7Z883f/jGlgLjQ23Uo1FG62PAzDnF5yvX6aQDe1LmInWVpCw6L3zhC/nkJz/ZFJ5HH330rP6+UqmwceNGwjCctaGzpaWF7du3c8899wBG4H7+85+fV57Hx8fJ5/O0lUqMeB7f+cEPiIeHZzRWzjd/uJSCba3r0cplYPKpfcPnKtfp83M3uPzyy+nt7W3+3he/+EV++7d/+7zKmbI2SIU7ZdG57bbbCMOQq6++mquuuorbbjs718373/9+rr/+el7wghfM2eC4b98+Pve5z7Fnzx6uvPJKvvWtb51Xnvfs2cPevXu58soree0b38hv/uZvouOYoK+vecz69eub84dfffXVPPOZz+TXv/71jO/Jew5tbicaRXTa7IFzleuVr3wlH/3oR9m7dy+HDh1q7s9kMtx1113ccsst7N69Gyklbzxt/cyUi5N55+M+F9L5uJeedP7kxScaGSE8fhx73TqcaYv1zodSmseHjqFkmS3FrbR6c6+us1JJ76elZ1Hn405JuVix29ux2tuJhoaIxsYW/HdSCra2dqG1zbHKcSL11PU2U1LOh7RxMmXN8MEPfrDp925wyy238O53v/ucv9PZsAFdrxMeO4Z0PWQu+5Rjbr75Zo4cOTJj30c+8hGuuP6ZjEfHOFruZ0db96wL/6aknAupq2SNkFZtLxw6ivAPHQIN7s4dSMdZ0N8prTkwdIJIjLI+20Vnft0Fzunikd5PS8/ZuEpWlsX90EdBKZAShAVCgrRMWja27Wn7krS0TbCcmWnLTdJuEpyptO2ZIG1ILaGUMyBsG3fbNvwjRwiPHsXdvh1xhoV5G0gh6Cl1cXCkxqnaIEU3T9Z5qsWeknK2rDDhvh2i2Sf6uWAICVYi4nYGnCw4OXAySZw1wS2Cm58WCuAVINMKXgtkWpJ0q0lbC7PKUlYHMpvF3bqV4OhRgr4+3O6FuT4822JjYRPHJ3s5Ot7Hpe2XIEXatJRyfqws4X73CdAKVGxiHSfp2FjijW0VzUw3QtxIhxCHyb7ApOMwSfsmHdUhCkwc+xD5Jh3WZoaJQQirEExCMAH+hPnt+XCLkCtBth1y7VNxfj0UOiHfaeJG2slc+PObcl5YxSLOpk2Ex48THj+Os2nTgsS7PZelUu9kQg3QN36c7tYtS5DblLXMyhJuIabcIisVrc0LwJ+AoAL1caiXwR+fStfLUBuF2ghUR0w8csSk/fLs35tpg5bN0LIpCUm6dTO0dUPrVrDdpS1rylOw29vRYUh06hTCdXEWuEzf1rZ2Hh+uMhGWGakVaM+e3dzfKSnTWVnCvRoQYso/nj+HFbwjHyZPGUt+YhAmB2HiJFROwvhxGD8GJ35u9s/8YSPmbdug1A2lHui4ZCqsQeI4xlqAL3mpsTs70UFAdPIkwnEWtACDlIKeto0cHqtzYvIEBTeHa6Uv4pRzIxXupcb2oHWLCWciCqByAsp9MHoUxo5OxYe/B5WvANN6BP3u38OQnbxUssb1YmeWzNd+2223sW7dOt7ylrcA8O53v5uuri583+drX/savu9z8803N6dK/b3f+z36+vqo1+u85S1v4fWvfz0AhUKBt7/97dx///3cfvvt3HDDDUuS/7NBCIGzeTM6igiPHUPY9oJWi886Np3ZTQzWj3JkrI9d7dtTf3fKOZF2B1ythDUYOQzDB2HoAI/ln8nTtnVCVOe2kzG/bCzGIoRpgBXTeuoIedaL0V1VyPL+XXO/bHp7e3n5y1/OI488glKKXbt28aEPfYgHHniAv/mbv0FrzUtf+lL+7M/+jGc/+9mMjIzQ3t5OrVbj2muv5Xvf+x4dHR0IIfjqV7/K7//+75/7uVkidBThHzkCYYS7Yzsys7B2isPDp6jpQfJ2C92tW1Zk/+60O+DSs3q7A6YsHCcLXVeaAPDYY7D+UuODr/RBXE0aeJVp2FURECZ/LIygN7pYNgX93LPT09NDR0cHjz76KCdPnmTv3r385Cc/4Tvf+Q579+4FzHSsBw4c4NnPfjZ33HEH3/jGNwDo6+vjwIEDdHR0YFkWr3jFK849I0uIsG3c7m6Cw4cJentxt29HLmCRg57SOp4Y9pmMygxMnmJjoXMJcpuylkiFe60hBO+/dNtT92tt/OthNekxk8R6mpg7OXBzprujkzP93c/CGnzta1/L3XffzcDAAH/0R3/EAw88wDvf+U7e8IY3zDjuwQcf5Lvf/S4//OEPyeVyPOc5z6FeN1WETCazIv3acyFdF7enh+BI75R4u2f2XUsp2Nm+iQMjASP1U2Qsj1K2dYlynLIWSIX7YkGIpG/6tOp8o4dMWIWgCuEkTA6ZxlMwg5PcQtJnPW9852cQ8ptvvpn3vve9hGHIl7/8ZWzb5rbbbuNVr3oVhUKBY8eO4TgO5XKZUqlELpfj17/+NT/60Y8ucOEvLDKTwd3eQ3DkCMGRIwsSb8eSbG/dyuHyEY5PHsOzXXLp4JyUBTKvcAshPg+8GBjUWl914bOUsmRM7yGTLZl9WkFYNyIeTJpuj8miAAhr5uAjJzdDyF3X5bnPfS5tbW1YlsWNN97IY4891lwlplAo8KUvfYmbbrqJz3zmM1x99dVcdtllPPOZz1zqki86MpNJLO8jU5b3PEPjs67D5sJW+ieO0ls+yq7STpx04FbKApi3cVII8WxgAvjCQoU7bZxcei5oY1LkTw1ACibMNhgh9wrgFcErooTDbzz96dxzzz3s2rXrwuRlhRNXqwS9vQjHwdu+HWHPX6kdqIwz7PdjCZdL23esiJ4maePk0rOo07pqrR8CRs47VymrF9szoz7btkHnFdB1lRkUlGk1LpZyP/t/8G0u2dHN8264ll1b1ptRrRchVi6H292NDkKC3l50NP+UrhuKLRSsTmLtc2SsP12yLGVeFs3HLYR4PfB6gG3bZmkcS1k7WI4R8lx74if3uaJ1C4cffQj8CoweAYRxqzTmcrG9i2YyLyufx+3eZuY16e3F6e6e122yra2Dg8M+9XiMo+VjdLduXpHdBFNWBotWJ9Na36m1fobW+hnrFzgMOGUNIIQZ6JNfD+07YMNuM5Izv950QRw/Bqceg8H9UD6WzPWy9i1Kq1DA3daNCgKCw0dQ86xCL4RgR/smbFqYjMocLR9PLe+UOVl+Z1rK2kJI4/Nu3QydTzOuldYtxuKePAXDB+DkL2HsSTOni1bLneMLhlUs4PX0gIoJjhxB1c4886UlBZe0b0nEeywV75Q5SYU75cJie8b67rgENiS+cbdgJuEaOQwDvzRD+deoiMtcDnfHDhCC4MgR4omJMx5vScGuVLxT5mFe4RZC/B3wQ+AyIUS/EOLWC5+tlDWJtI1fvH27cam074RsqxHtGSI+vqZEXHoe7o4dCMchOHqUuDzHDJGN45viXUzFO2VWFtKr5D9prTdqrR2t9Rat9eeWImMpq4877riDpz3tabzqVa9Ca41SmjhShEFM6EcE9Qi/FuFXQ+rVmFqUoWZvpF68HD+3E99eR1D1CYaOEZ54gni0Hz3NJ/6+972Pj33sY8tcynNDOo7p253NEvT1EQ0Pn/l4KdjVvjUV75RZSUdOpiwYrTVaaeJYo2KNilUSm/DXd/w1X/nS37NtSzen+iozJi9cGIUkADFmapVxhWQMaQnqEwG2CJks+9iOxHIkli1XTe8LYdu4PT2EfX2EJ06g6nWcjRsRcnb7qSHeB0b6mIzGODyq2F7avCL6eacsL6lwpwBGlBsCHMcKFRlhjqMpgY5jPWuPECEEf/rut9L7ZC//zx/9R15+8y309h5h/2O/Iooj3vOu23jpS1/GF7/0t9x3333EKmb/r37FW9/2NoIgYN++fXieyzfu/Satra187vOf4+677yIIAnp6evjUJz5BxsoSKZ8gdBivlOnt7eVd73kHw8PD5HI5/sftn+CKK6/Ay7i4GWfFirmQEmfbNsTgINGpU+haHWfb1jmHyDfE+9DocepqjCeGA3aUtuGmIywvalLhXoP89//1K/YfH5+xT2sNTd3VJtaJFX0Gy7ihf5d3FXnnCy5DWhJpiSQkaSm4+4uf48HvP8D3HvoeH//4x3nh776AL+77W8bGxrjuuut40YtvwnYs9j/2Kx5++GEqlQpXX301733ve7n//v+f97znPXz2c3fyute9jt953nP5D7eYGQL/6q/+ii999Su89tZbzVrRMkYKnz97x9v5yw9/mB07dvDII4/w3/78bdxzzz1M1Ey5hLCwLAvHsfEyHp7nrpjJq4QQOF1dyGyWsP8YwaFDOFu2YhVnn9NbSsEl7ZvoL3uMR4McHD3MtpZtFNx0bpOLlVS4VxlxrPAnEz/xREhtwsRhLmJipI5SGr8aEQXxvN2lhTD/SUEy06tI9vEUi9XN2hRKC5tv+jvf+Q733XcfH/vYx9BaU6vV+OUvf0mlUuH666/H931c16VYLHLjjTfiui7XXHMN+/fvp6Ojg1//+te86U1vYmxsjImJCV74whfStWED+UKRQj5PPuvx05/9lDe/4bUkKo0fxpRaiviBJgxD4jgmikKiKKBWrwIghcRxXTIZD9d1sW17WS1zq6UFsdMjfLKP4Ggvdmcn9vr1s+ZJCMHWtnWcmvQYrB7j6PgRunKbWJdLl0C7GEmF+wLScD9EoSIKYuLQNNRFfiOOk4a7JNQjglpM4McEtYiw2ZiXhFpE5M8+lPza/1yiOhEipeBPnn3JlFUsxWlWcrItL4xgxXFMHMfcddddbNu2jTg2+RVC8OMf/5h8Pk+pVMJxHBzHYdOmTZRKJfL5PEIIPM/j1ltv5Zvf/CZ79uzh7rvv5sEHH5z6ASFQdoa2thL/+ov9Zg3P6rAZsTl+kKxbgGIHZNahEIR+RL3q4/sBcRzi1318v97Mk+dlyGQ8MpkMcg5f84XE9DjZTnj8BNHgILpWM4sQzzHScn2+SNbu4eh4Hyerx6iFPltaOlesayjlwrCihLtv/whK6anWc520b+lpVXumqvyN40yj2dRxjeq/VtNjc0yjt4NW07Zj3TwmjjU6NscolaQbft9GQ1ykkgY64wOOI2X2RVPbUaiIF2D1no7lSNyMhZuxcZK4dX0WL+/g5WwyORs3a9LZokO24JIpOPQNHKZzW3ERr8bC0NpYuPV6HaUUp06d4oYbbuDTn/40H/3oR8nn8+zfv59rr72WYrGI67pks2eu4lcqFTZu3EgYhuzbt4/NmzfP+LylpYXt27dzz733csstt6AzbfzbIz9jz6VbjIiPHQXRj8yW8HIdeB3GBRFHyvRsqQb4QYAiol6rUa+bgTGO4zZF3JlniPpiIiwLZ8tmZC5LODCAOngQe+NGrNbWWQW54GXYVdrO4bE+xsMhDozU6GndjGunfu+LhRUl3P/4//0bUbg8/XeFNNapaFqpU7GQAsue6du1krSTs5C26d1gOeY4y5bNXg+2Y2G707ZdC8ezcFwLuxnLplBb1rlZfeLk0llcSil838f3/aZgNygUCnzgAx/gT//0T3nuc5+L1pqenh7+4R/+YcHf//73v5/rr7+e7u5udu/eTaVSecox+/bt401vehMf+MAHCMOQV77ylex5+nuh0GVmMKwOJ2HIrBaU68DKlsgWXLIF17xw/Bh/MqRW81E6JNQRYRhQqVSwbZtsNrtkIi6EwO7oQObzhMeOE/b3o8pl7E2bZp3nxLVtLu3ooXd0gJoa4cDYQdZnNtBZKF3wvKYsPytqzcmBI2VjYgsQ5r9m45gQU9tNKyQ5TsjEPyunHydm7JuKjR9XSjEl1hfIbbCUXOhpOOM4xvd9arUafjLvRsO1kclk8DxvxTT+NYkjM0KzOgxRDZCQbYNch5kAK7mPtNZEQYw/GVGvBUQqRIsILY2bZ6lFXGtNPDxMeHLQTAWzYQNWqTSnO2S0NsnxieMgAhxRoKdt03n3OkmndV16Vu2akxu2p8s3rSTiOKZer1Or1QiCAAApJfl8nkwmg+u6K9u3atlQWA/5dWaZtuqwEfLaCFieEfBcCWG5OJ6N49nktUcUKPxqSG0yINYhsY6oRJWmJZ7L5chmsxfsRSWEwF63DlksEh4/Tnj8OHG5jLNx46wLEpeyeVq8nfSODVBXoxwYPcj67EY682nD5VplRQl3yvITRRH1ep16vd4Ua8uyKBQKTYtzRYv1bAiRrKWZg5ZNZkWf6jBUjpvgtZih+JlWhJDGleVZ5Ns8406pRtSrAbEOiHXE+Pg44+PjTX99Npu9IA2b0vNwe3qIR0eJBgbwDx7Eaithd65/Sr9vS0p2tm9itNbK8YljnKodY6w+xubiBvLuwnoDpaweUuFOIYoiarUa9XqdMDSLB9u2TbFYJJPJLHu3uUVFWoml3QFRHaojJoz2mhV9siUj4k4OIQRuxsbN2BRKHmE9pl4NqVcDFCGBHxIEAeVymUwmQzabxfO8RRVxIQR2eztWSwvRqVNEIyPE5THsjg7sdeuessKOsb4v4ejYADU1Ru/4ITzZwtaWLjz7zOtgpqweUuG+CJneE6RerxMlq7Q4jkOxWCSbzWIvYMmtVY+dMRZ4caPpTlgdmWrQtDzIlSDbDrZnRDxr42Ztiu0ZglpEvRrh13xiQuo101ArEGSyUyK+WC88Yds4GzdidXQQDQ4SDQ0Rj45irVuH3d6OmOa2saRkR/smqkEH/ZWT+Gqcg2MVclYbW1o6cayL4NqucdIreJGgtW72ApneE8R1XVpaWpqW9UWJEJBpMUFFUBszvvDKgAlOzgh4tg0s4yrycg5ezkGrzNTEWXUfJUJq1Rq1Wg0hRNOVsljtAdJ1cbdsQa1bR3TyJNHJk8RDQ1ilElZ7+wwXSs71uLRjG+P1GscnBqjGozwxWqZot7Ox2JEK+ComvXJrmCiKmt32fN9v9nvPZDIrtyfIciNt05iZXwdRAPVRqI7CeL8JbgEybWY6WstFSEEm75DJOxRV1vQTn0z6tYuI6mSVarWKEGKGO+V8RVxmMrjd3cSTVeLhIaIhE6yWFqyODmQu1/yNlkyWlsx2RqoTnKyepBINURkdxpNFuvIdFL3cYpy5lCUkFe41hNaaIAialnXDBSKlbHZnc113WUYIzseDDz7Ixz72sbPq733BsV3TL7zQZXql1EbN3OENEXdyxgrPtIHtIaUgk3PI5BxaEhGvNyxxplniJN0os5nzHrFp5XNY+W2oICAeGSEeHSUeH0dmMliJb7zhB2/PFShl84zWJhmqDeOrCk9WxpGVDCWvRGehLZ15cJWQCvcqJooijh07Rm9vL7lcjhMnTjQ/a7hAPM9bW42Ly4WTNaFlE4R10zOlPgbjx02wPdM7xWsBt4CQsulOadHZqd4p9TqRCozLKhl6b1sO2WyGTPbcG4Kl6yI3bMBev564XCYaHjZdCU+cwCoUkK2tWMUiwrJozxVozxWohyEDE0NMRmWG/RMM+4NkZIFStjWd+3uFkwr3KqJarXLs2DH6+/vp6+vjySefbFrVL3rRi8jn83iet2xWdW9vLzfddBM33HADP/rRj9izZw9/+Id/yF/8xV8wODjIvn37AHjrW99KrVYjm81y1113cdlll834nsnJSf74j/+YX/ziF0RRxPve9z5e9rKXLXl55sTJgLMBihsg8o0V7o/D5JBZVxMJXiER8iLC9pq9U4pkiEIzF0295hOEAZGOqExUqExUEELiOi6ZrNd86Z4NwrJML5RSCV2vE5fLJlQqhEJgFYtYra3IfJ6M49BT2ohSXQxOlhnzR6mrMicmywxMDvKer97NLZf/e2656gbs1KW2okiFe4USBAGDg4OcOHGC/v5++vv7GU5WTRFC0NnZydOf/nR6enro7u7m6NGjtLYmA5j+6R0w8IvFzdCG3fC7H573sIMHD3LPPfdw5513cu211/LlL3+ZH/zgB9x333186EMf4gtf+AIPPfQQtm3z3e9+l3e9613ce++9M77jgx/8IL/zO7/D5z//+ea0sM9//vPJ5/OLW6bFwPag0GmCis1we79ill/z+80x0jYjNd0CuHlsJ4fd4pFr8aaG3ldD6n6dKA7xlY8fNCbCkjh2Q8gXPqOhEAKRzSKzWeyuLlS1iiqXicfHicfNlL8ym0UWCsh8ga58KxuKJYIo4lR1jEFGeKL6z3zoX/+Jv/xZCxvdPVy/8VpeccVz2LNx+wU7nSkLIxXuZUYpxfj4OIODgwwMDHDy5EkGBgYYGRlpVlfz+TxbtmzhmmuuYcuWLWzatAnP85Y557Ozfft2du/eDcCVV17J8573PIQQ7N69m97eXsrlMv/vq1/NgQMHEEIQhCETUcxkHBNqzUgY8Y/33883vvUtPvzRjwJQrdV55OAhLr38aY0ZEUhmpE3SyTQGgBQCK4llss8SArkUriJpQabVhFaMNe5XIJg0gl5P1poU0vjH3RzCyeE6OdxShqLIopQm9CP8WoDvB0RxSKDqBGE9+RGBLW0cx8HLuHiZ+RuYhRBY+TxWPo+9cSOqVkNNTKAmJohODcGpUyAlMpdD5nJsyGYp59r55//wL3z2J9/mX/oe4HjwM77R/32+0f9xZNzB5szVPGvTdbzo0mexd8P2FdluspZJhXsJUEoxMTFBuVxmeHi4GYaGhhgZGWm6OwDa2trYsGEDV111FV1dXWzcuJG2traz83suwDJeTGKtiZRmMoqxXY+hICTSmpqGspAcnKxztBYwGYS8+R3v5PJn/Tv++9/u49jRo7z2xTdxqOpzoh5SixV9tYAgVnz4C/vo2XXpjN8Z8MNzzqMQYAuBJcBCYAmBLUhigS2TODnOXgyxt71klft1ZjsOwJ8wQh5OwsQpmuu7CQucLNLJ4dkZvEIG2opoYREGMX4tIEiEPIpjojik5lehDCCwpIVt2Tiug+u5uK4zq5gKIbByOaxcDjo70XGMmpw0Qj45STQ4CEB08iSTb3s7t+7ezX/Z/ds4l97KD2Wd+4Z/wb8NP0Jf/Yf0Hf3ffO0oEOcoiG62FS5lT+cVPKfnN7huy67UvXIBSYX7PInjmMnJSSqVChMTE814bGyMcrnM2NgY4+PjzXmpwTw8pVKJdevWsXPnTjo6Oli/fj1dXV1kZpmLYrlQWhNqTahMHE1Lh4lYh1qjEu05VgsIteJY3QhsoBSh0iDAs4wFHFQqXLptK5szDl/+2t/hCMHOnMfxjEPeklxeyPCS372J+z//We745CcRQvCvjz7K3r17acioboRkmt/GttImzyrJe9yItXm5xEk6QhNoRVWZ/XO1w8lpIu7MIuy2AAfMy0CIJH9JNaCRhqmZ0izXjMrMtScFUaahM6wmoZb4yKcyJKSNa2dw7QzkXbA8lMwTxha+HxEEAXEcoeIYP67jh3WYbPy6MCsBSQvbtrEdG8excVwbKc1ancKyTBfClhaTpThG1erIapXM5ZdTfeQRxr/9bQC2Af+1UMDbuRN7xws4VHT5V2eCf5PDPJE5wa/4B/ZXv8Xf9YJWDq7uos3exKb8VnaWtnN11y6u23wpm1vaUwv9PFmQcAshbgI+AVjA/9RaL61Jd4HRWjf7PNfr9afE9XqdarXaDLVajWq1yuTkJNVqddbvLBQKtLW1sWnTJq644gpaW1tpa2ujvb2dUqm0rP2nVSLCcwlxQ6zjWQRNCHPTOAJcICfAFhpLa2JiHGC7DpBaU9AxHZFPV22CenUCSyn+25tezxvf/F/57Mdv57d+6wa0iolHh1CVcXQY4A8P8fY3vZF33HYbe666Cq0127Zt5etf+Uoy82My66OQyUyPJi2lwBISIZMgZllE2EzObgbZqBhUhFYxWkWoJNYqBhWjdQxaIWYEjaARFo5GoIUAZGN6S4SQIGQzbljcuPmpfGqTR+LQCLs2g6Yk4AGesMzLwHPQlkOMS6hsglgSxppYKZRShCogjH3wZ2QqOUcSKSWWNEu9WZbEsi10NkvbBz7E5mKOeHgY/+Ah/EMHCQ4dxj90iOr3v0/n0BA3Ajc27o1ikfq6EgMFh+NZxYlMnZO5XzFS/DE/K2oeyMN4DhQetiqRk+toddfTmd3A5sIGNrV0sqVlPd1tXexo76I1k/Yvn4t5p3UVQljAE8ALgH7gJ8B/0lrvn+tvznVa15GREeI4RiU33PTQ2D89nh6iKHpKHEURYRg+JQ5DM8fE9DDfeZBSNmeFy+VyzVAoFCgWixQKhWY6n88v6ShErTX7H3uMSy67vCnGzVgpI9KqIdYwY8ZzPZWQ2giw1AqhFFIrZBwjVYxQMVKZ/WLaHzfSIvkikSx0IaZbjWJqfl4Tian9zSzo6YYmU+ti6vmvjdBItImTYImZ2+ZzdUbB1UjjpxZTsRAWyIa4SjQChTBWPRAjjKVPYu1rjcLUQrQ29QHZFHzVTEutkSgkGkubWGpzzs0vzE/jjE/fM9vfmV+2iXGIsImTX471VFk0oIVIai+Co0ef5P777wctsHCwpYstXVzbw3U9PC+DZ9k4KsYNApx6DXtiHLs8ij00iD00gF0exQnquEENK3npaAE1z2EiKxnPwHg2ZiIbM5GFqgdVT1DzoOpCzXGpO3liL4dyC8hMASvbgptro5grUXQLFN08QD31+wAAEptJREFUbV6R1kyB9myR9lyR9myR1kyOtmyenLMy24JmY7Gndb0OOKi1Ppx8+VeAlwFzCve5MvLN3UitzA0phHlwBWgtmjcV2lhZFsZXqabZQFqLpnWjaTxoEt186CxwLPAsEA4ICy0dEC5aOGgrA5aHsL0knUXaWdOQZOVQwiOeFiIsAhQD1IknFKoySXx8mFhbxFoSKYtIySRowsgIaRArwkgRhDF+GBFGEX4YUw0j6mFMLVL4kcKPFUGsE5cDREoTK4hVQyQaKwHB/3zxRuIT42c6vU3mEgUNTHnbZRLsmZtngUgaCAUCKZOGQ5EsUJG4F6QUWNNDw4InxkYhdZRYyEmII1BhEkegoznECjRWQxqJEChtRDZWoBSYReuTe0gLZns9CKkRUiOlRgid6LdoWqpmjndpytbYnlYjAEEsRFPk4+QcKwQxxq0Ta4gbceLqMTWDGKGVKUUi6hbKCL1WyGY6To5pvARUM5a6cQZCLEJmTDN1hrfDGOO8U3yKQNiEwiEUNiEOUWwR1W3CukUobGIsYmERYREXJHHRIt5iUUOiaCGmDZNrkcQSrZNXlhY4WLRpaNXmGpBcE62TJuhYQBX0RHJRqYGqoTkBDbcYAoVmEBhI3v8KgRbmRarllHsNzMtDawFCo2VDP8zp0A3DQmBqQcm2+SyJpUzWC5hyhTUcZdK2ecuf3z73iV0kFiLcm4G+adv9wPUXIjObngzJ6AApVl/n/1gLImxCzE1sHhObSJs4xJ6xP8ROHgbzAASYhyPCTh4WE0eN2LIJbTt54CVKTKuwC0FBvpwOu0LjFmr0smgICQ3XQdPFkLgTZMOlIKbdjMm2EDQtX6B56zeXkDNhRlor0CpZVV4lYarqL5R584hEWEQiOs0g5l4BqfnwSxstbLSdQVgOwrIRloNlO0jLBWkjpGVeHGe4Zlqb2pyOFTqp2Zk4Tpa2i822NvtN0MRRZNJaJced26pNp70aZ8+jSAwRIZtpJQSxkGhhmfMgphksidBoKZr7zT9zt8gpM8ek9ezpipzk820vIaN8PBXgqRBXhzgqwtMBrk62dUhW17CJcXWErSNcImwdJy9f8wK2iHGYfb3UeU/S9Hg5aTwHZyjGqaAVWBnCPZdBM/MgIV4PvB5g27Zt55SZZ7h3Gyuy+aMaCw1Cm+uWVHsFpnoshKluGpEyWbKEMvuTanFzGzWt2qwQQpljkmOnC4exI6bi6TegLeJkf4yjY7OtpyqhjjaxrSMyyc3tEpJRAS4hro5wdUBe13FVhKNDHB2Zv1MmtlSMpRVW4p5YyD37mH4+m+JTK36EpEYg5HT3g4WWLlpYKGERIFHCIkYSaYsISagtAiUIlTAuH6WI1Wwvd4UUPrYVYEuJY5neIpYlTa+RRrAklmx8ZpuWm/MpU8Odk7y4mmucNvcZe++p+5j5EmRqHdVpH05riE1qCTDNPSNmbJsahKlRmP16ygJNPpurdjG9POU4y0dOvGLOY2wZYokYW8ZIqbBEjCUVVrLdcF1ZQjefT5nUgRyhsJNnzhYKp1kvUklNWhlXlzbPf8PVJUTjO3TyvOukRqdNGwQgabQD6MQg1jPcd40XmE6OQWiEbjQrT9nlU66/xnc0T87UtZl+nZpYvO0M53axWIhw9wNbp21vAY6ffpDW+k7gTjA+7nPJzOXP6yZMToxMqiXT++xKRNOKlNP68Fpier9d0fxbU/WeCo3quSUEtpTNbmCWMA+yk/QWsDC9BWylsRRYscZR4EQKOwY7VDiRxooUThDj+grHj7HrCrceYVVjnFqEmAxRtWiW1xwgQeZdrBYXq+hitbpYpQxWycNqy2CXMsiCY6rbKjYNVCqEOETHdVRYQ0c1dFxHxz5u2WFIdNBeKpgbs7m6ciNuejJPE4vpxzHjb5q+52aq4Yee6ssxPW4KVHKXPzVu+LYthLCnxTZC2sgkbQsbR9hIaQOzNDKS9BaJjYiHShMl6SieSvuRYjJWRLOKvMESp7lq5Ex3jkxqLJacuicRU7UawWm+euPnaz7qjbOjnpLWU71gtEapaWkNsdIzPmtcjfkwhk1iuIgpY8UWKtmfiJdIRK/R/71RU9MwMV5lMhzkju6HyUQSVzl42sGLbRzl4CgXS7tYThbLySLdLLabQbo5LC+DlckgPRvhWkjPQjgWwpNm27EQjpwK9lQaS66JZQSXgoU0TtqYxsnnAccwjZN/oLX+1Vx/c66Nk2sRrTSqFqGqIaoaoSoBcSUgHjexaqTLPqoazfxjS2C3Z7DXZbHX53DWZ7HXm7SVn7mmYBiG9Pf3U6/XWU6aLwwSd8mM2IRGempfzGlNptMwXdoQEoGVuHhMDFYzbbZnf+i1niaSSW+Z0wVzxjGNhsXT20sXmab4i2npRFSnPK9GgGe05oiZxxhDpuFfb5yLJNbStAspAVqgYxBq2nt8RobMQCa7Lmg/6eDmPGTRxSq4yIKDzNnInIOVsxEZOxXZRWZRGye11pEQ4s3A/ZhK5efPJNopMxFSYOWdpwjtbCg/Jh6rE436xKMmjoZrRKdq1J8YZXr/PJmzcTbmcTYWTLypQM+2bsQ5rhK/3GgdE4SjhMEwQTCEH5wiCE4R+Kfwg8EkPkUQDBJFT131XQgLxynhOh04bgeu24HrmNh22nDsFmy7FdtpSdIt2HYBIc48T3YQKapBRDWIqQbxlFWvNFFizYexQmsfrWpJqKLiKkrVQE8g1RjoMYQeRahRiIchHkRFp4BgRsOZQeK6HTjuely3A89dj+uuw3XXJWVb1yyb47QjpU1cCQgHJglPTE7Fp2oQTb0QhSuNEdCRxSp52G0ZrDYPq80zNbxsOqxjtbCiVnlPmRsda+KxOuEpI+TRYJXgxAThQHXq4bQETlcOd2vRhG0t2Ouya84yiuM6QdAQ9KEkHiQIhwmCYSP+4TBBMEIcT8zzbQIpM1hWBik9LCuLFO5UjwGmxxqlQpTyp4UApXzmrjEYLKuA67TjuKXkBdPeFOOZoQPHKZlaxlzlnwgI+irNEJ6YRE1MjSqVLS7OhjxOZ87U0NZlcdZnkcUVvrjzRc6qXeU9ZW6EJbA7jLXE5VP7dayJhmuExycIT0wSHJ+g+vNTTD48YP4uYzVF3Otpwe1uQbqreyiyZWXIZreSzW6d99g4rhNFZcKwTBSNE0XjhNE4UVgmjieJVR0V12fEWplFkmfzK0vpJsGbFlxsK49lF7GnB6uI47ThOG1IeW7rPepYE56YwD8yTtA3TtBXIR5NRtJIcLryZC5rT2pfeZwN+QXV7lJWN6lwr3KEJXA6czidObjG7NNKEw3VCJ6smIf9yQqVf3mSigakwN1SwNvRhrej1Qi5t7qF/ExYlrGmPa9rubOyIHSsCPon8I+UCY6U8XvH0b7pf2a1eeYl/KxNuFuLOJsLq/4lnHJupMK9BhFySszzzzCCpfyI4GgF//AY/uEylYf6qTzYBxLcLUW8XSUyu9pwtxZXrZ98NaK1JjpZpX5gjPqBUYIjZXRo3C52Z5bcNevxdrTibW/Falk9owBTLiypcF8kSM8mc2mJzKUlwDSEBk+O4x8qUz80ZizyB55EeBbezjYyu9rwdpVw1mWXOedrj3gioH5gDP/AKPUDY6iKcc3Y67PkntE1JdSFc3OvpKx9UuG+SJGeRWZXicyuEq2AqobUD43hJ5Zffb9ZtMHqyDQF39vZllbNzwGtNEFfhfrjI9QfHyU8ZhpMZc7Gu6SNzK4S3q427LaVMzNkysomFe4UAGTOIbd7Pbnd69FaEw/XjYA/Pkr1pyeZ/OEJsATe9lYylxkhtztzaS+FOYgnAupPmPPnHxg1ffQFuNtaaLmxm8ylJZxNhTXX4ydlaUiFO+UpCCGw12UprMtSeNYmdKjwe8vUHx+l/sQo5W8fofztI1itrvGNX1Yic0npou4HrJUm6K+Yc/T4iLGqNciCQ+bydjKXtZPZ1YbMpT0+Us6fi/dJS1kwwpFNtwpANFan/sQo/hOj1H4xRPWnJ00j59YWU/Xf2Ya7rYiw13YjZ1T2jWvpoDkXTat6a5GW53eTuSy1qlMuDKlwp5w1dluGwnUbKVy30XRf66sYt8ATo1ONnI7E3d5KZmcb3s7WNSFgqh7hHy5TPzCKf3CM6FQNSKzqy9rJXF7Cu6SU9qNOueCkwp1yXghL4vW04vW00npjD6oa4h8pUz84hn9ojPI/HTHHeRbutmQgUHcL7tbiinetRGM+wVHTlzp4skJ4YgIUzZdS/roNeJeUcDakvv6UpWVlPzkpqw6Zc8heuY7slWaB3Hg8wD80hn90nODo+NRAIAF2Zw53S9EMz96QM6P+ikvfBU5rTVwOCE9OEg1MEhybIDg6Tlw23fSEK3G3Fik+Zyvezja87pY17wZKWdmkwp1yQbFaXHJ7O8nt7QSSgUB9FYKjFYInx6k/PkL1Zyebx8u8g9OVw+7KYbd5WK3Tg3vOg4N0pMwsjOM+cdnE0XDdTMg0UEXXp2ZmtFo93G4zPYDX3YKzsYCwUos6ZeWQCnfKkiI9m8wlphdKg3giIByoJiI6SXiySvXRQXT9tKVGhBF26VkItxGkme/ZkaA0OlLoUE3FoUJNhqjJkNMRGQtnQ57cNetxuozF73Tl0p4fKSueVLhTlh2r4GJd4pK5pG3GfuVHxGOJhVz2icZ8VCVA+TE6iI0w+zGqEqLDGKSYmpzflsiCA7bE6mkxC1Y0LPcWs4CFyNqpbzplVZIKd8qKRXo2ssvG6covd1ZSUlYUaQtLSkpKyiojFe6UlJSUVUYq3CkpKSmrjFS4U1JSUlYZqXCnpKSkrDJS4U5JSUlZZaTCnZKSkrLKSIU7JSUlZZUhtNaL/6VClIED03a1AuUzpKfvWwcMneNPT/+esz1mtv2n7zvT9mouy3zp8ynHmfK5kM9XUlnO55rM9tnFcn+dvn16WS70/XWmY1bS/bVLa926oCO11osegDvn2p4tfdq+ny7W757NMbPtP1M51lJZFnB9zrkcCynLmT5fSWU5n2tytvfTWrq/5ivLhb6/FrMsy31/NcKFcpX8rzNsz5Y+/fjF+t2zOWa2/Wcqx+nbq7ksC0mfD/N9z5k+X0llOZ9rMttnF8v9dfr2ai7Lct9fwAVylZwPQoifaq2fsdz5WAzWSlnWSjkgLctKZK2UA5auLCuxcfLO5c7AIrJWyrJWygFpWVYia6UcsERlWXEWd0pKSkrKmVmJFndKSkpKyhlIhTslJSVllZEKd0pKSsoqY0ULtxAiL4T4WyHEZ4UQr1ru/JwPQogdQojPCSG+vtx5OV+EEL+XXJNvCSFuXO78nA9CiKcJIT4jhPi6EOJNy52f8yF5Xn4mhHjxcuflfBBCPEcI8f3kujxnufNzPgghpBDig0KITwohXr1Y37vkwi2E+LwQYlAI8cvT9t8khHhcCHFQCPGOZPfLga9rrV8HvHSp8zofZ1MWrfVhrfWty5PT+TnLsnwzuSavAf7jMmT3jJxlWR7TWr8R+H1gRXVJO8tnBeDPga8tbS4XxlmWRQMTQAboX+q8zsdZluVlwGYgZDHLcj4jls5xdNCzgd8AfjltnwUcAnYALvBz4ArgncA1yTFfXuq8LmZZpn3+9eXO9yKW5XbgN5Y77+dbFoxR8H+AP1juvJ9rOYDnA6/EvExfvNx5P8+yyOTzLmDfcuf9PMvyDuANyTGL9uwvucWttX4IGDlt93XAQW2s0gD4CuZN1Q9sSY5ZcW6dsyzLiuZsyiIMHwH+SWv9yFLndT7O9rpore/TWv8msKLccWdZjucCzwT+AHidEGJFPS9nUxattUo+HwW8JczmgjgHDRtNjokXKw8rZZX3zUDftO1+4HrgDuCvhRD/nsUbHnuhmbUsQogO4IPAXiHEO7XWf7ksuTs75rouf4yx8FqFEJdorT+zHJk7S+a6Ls/BuOQ84B+XIV9ny6zl0Fq/GUAI8RpgaJr4rWTmuiYvB14ItAF/vRwZOwfmelY+AXxSCPFbwEOL9WMrRbjFLPu01noS+MOlzsx5MldZhoE3LnVmzpO5ynIH5qW6mpirLA8CDy5tVs6LWcvRTGh999Jl5byZ65r8PfD3S52Z82SuslSBRW/bWinVqX5g67TtLcDxZcrL+ZKWZWWyVsqyVsoBaVnOmZUi3D8BdgkhtgshXEwjy33LnKdzJS3LymStlGWtlAPSspw7y9Ai+3fACaa6x9ya7H8R8ASmZfbdy91ynJYlLctyh7VSjrQsix/SSaZSUlJSVhkrxVWSkpKSkrJAUuFOSUlJWWWkwp2SkpKyykiFOyUlJWWVkQp3SkpKyiojFe6UlJSUVUYq3CkpKSmrjFS4U1JSUlYZqXCnpKSkrDL+L1TmQaXL+qGdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc579f526d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Regularization Path RIDGE of country coefs')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc578a53550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "alphas_ = np.logspace(0,6,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    if \"country\" not in label:\n",
    "        plt.plot(alphas_, y_arr, label=label)\n",
    "ax.set_xscale('log')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "...#modify\n",
    "if \"country\" in label:\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.title('Regularization Path RIDGE of country coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas_ = np.logspace(-2,3,base=10)\n",
    "model = Lasso(fit_intercept=True)\n",
    "...\n",
    "country_alphas_ = np.logspace(-5,0,base=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc5787aa5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas_ = np.logspace(-2,3,base=10) #se escoge\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True) #se escoge\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    yhat_train = model.predict(X_train_scaled)\n",
    "    yhat_test = model.predict(X_test_scaled)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - y_train, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - y_test, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge/lasso')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge/lasso')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = linreg.predict(X_test_scaled)\n",
    "mse_test = np.mean(np.power(yhat_test - y_test, 2))\n",
    "from sklearn.model_selection import KFold\n",
    "K=10\n",
    "kf = KFold(n_splits=K)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(X_train_scaled):\n",
    "    linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "    linreg.fit(X_train_scaled[train], y_train[train])\n",
    "    yhat_kfold_val = linreg.predict(X_train_scaled[val])\n",
    "    mse_fold = np.mean(np.power(yhat_kfold_val - y_train[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / K\n",
    "...#or MAE\n",
    "mae_fold = np.mean(np.abs(yhat_kfold_val - y_train[val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e98cd7b4e141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#predict score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;31m#armar un raking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muniv_chilenas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"country_Chile\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrannking_univ_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniv_chilenas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"total_score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mranking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "df_test[\"total_score\"] = model.predict(X_test_scaled) #predict score\n",
    "...#armar un raking\n",
    "univ_chilenas = df_test[df_test[\"country_Chile\"]==1]\n",
    "rannking_univ_ch = univ_chilenas.sort_values(by=\"total_score\",ascending=False)\n",
    "ranking = 1\n",
    "for index,row in rannking_univ_ch.iterrows():\n",
    "    print(\"%d - Institucion: %s\" %(ranking,row[\"university_name\"]))\n",
    "    ranking+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Análisis de audios como datos brutos\n",
    "\n",
    "Distintos tipos de datos han sido tratados en el área de Machine Learning, donde el análisis de estos y\n",
    "el manejo para poder dejarlos en una representación que se pueda entregar como entrada al algoritmo es\n",
    "crucial. El manejo sobre los datos brutos se denomina pre-procesamiento y existen distintos dependiento del\n",
    "tipo de datos y los distintos diminios de problemas, tales como imágenes, audios, texto.  \n",
    "En esta actividad se trabajará con datos de audios los cuales son directamente extraı́dos desde datos fuentes\n",
    "*.wav*, lo que corresponde a una señal de sonido en diferentes tiempos.\n",
    "\n",
    "<img src=\"https://cdn.shopify.com/s/files/1/0977/4240/products/il_fullxfull.1054777221_nym4.jpg?v=1527718941\" width=\"40%\" />\n",
    "\n",
    "\n",
    "\n",
    "El *dataset* se denomina **Heartbeat Sounds**[[3]](#refs) y es presentado en la plataforma Kaggle a través del siguiente  __[link](https://www.kaggle.com/kinguistics/heartbeat-sounds)__. Este dataset consta de grabaciones de sonidos de latidos cardı́acos normales y anormales, con distintas categorı́as para los latidos anormales. Para la tarea se trabajará con el *dataset A* presente en la data, el cual corresponde a datos generados desde la vı́a pública mediante la aplicación de Iphone iStethoscope Pro. El objetivo será el de clasificar cada sonido como latido cardı́aco normal o una de las las subcategorı́as de anormal (*Murmur, Extra Heart Sound, Artifact*), por lo que se trata de un problema de clasificación múltiple con 4 clases. Las distintas clasificaciones para los sonidos son explicadas en el sitio de Kaggle.\n",
    "\n",
    "Para leer y trabajar los archivos de extensión *.wav* se utilizará el siguiente código:\n",
    "```python\n",
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "SAMPLE_RATE = 44100\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b\n",
    "```\n",
    "\n",
    "> a) Construya un dataframe con los datos a analizar. Describa el dataset y determine cuántos registros hay\n",
    "por clase.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')\n",
    "```\n",
    "\n",
    "> b) Lea los archivos *.wav* y transformelos en secuencias de tiempo. Realice un *padding* de ceros al final de cada secuencia para que todas queden representadas con la misma cantidad de elementos, explique la importancia de realizar este paso.\n",
    "```python\n",
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelledtested')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='path/to/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series']=new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))\n",
    "```\n",
    "> c) Manipule los datos y cambie las etiquetas de los audios por otras asignadas por un doctor experto [[4]](#refs), el cual afirma que estos cambios son requeridos. Vuelva a determinar cuántos registros hay por clase. Nótese que ahora son 3 clases ¿Explique la problemática de tener etiquetas mal asignadas en los datos? ¿Un solo dato puede afectar esto?\n",
    "```python\n",
    "new_labels = ...\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]\n",
    "```\n",
    "\n",
    "> d) Codifique las distintas clases a valores numéricos para que puedan ser trabajados por los algoritmos\n",
    "clasificadores.\n",
    "```python\n",
    "new_df[\"target\"] = new_df[\"target\"].astype('category')\n",
    "cat_columns = new_df.select_dtypes(['category']).columns\n",
    "new_df[cat_columns] = new_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "```\n",
    "\n",
    "> e) Desordene los datos, evitando ası́ el orden en el que vienen la gran mayorı́a de las etiquetas. Cree la matriz que conforma a los datos en sus dimensiones sin preprocesar, es decir, cada ejemplo es una secuencia de amplitudes en el tiempo. ¿Las dimensiones de ésta indica que puede generar problemas? ¿De qué tipo?\n",
    "```python\n",
    "new_df = new_df.sample(frac=1,random_state=44)\n",
    "X = np.stack(new_df['time_series'].values, axis=0)\n",
    "y = new_df.target.values\n",
    "X.shape\n",
    "```\n",
    "\n",
    "> f) Para pre-procesar la secuencia en el tiempo realice una transformada de fourier discreta [[5]](#refs) para pasar los datos desde el dominio de tiempos al dominio de frecuencias presentes en la señal de sonido. Visualice el cambio de representación.\n",
    "```python\n",
    "X_fourier = np.abs(np.fft.fft(X))\n",
    "```\n",
    "\n",
    "> g) Para seguir con el pre-procesamiento realice un muestreo representativo de los datos a través de una técnica de muestreo especializada en secuencias ¿En qué beneficia este paso? ¿Cómo podrı́a determinar si el muestro es representativo?\n",
    "```python\n",
    "from scipy import signal\n",
    "X_resampled = []\n",
    "for i in range(X_fourier.shape[0]):\n",
    "    sequence = X_fourier[i,:].copy()\n",
    "    resampled_sequence = signal.resample(sequence, 100000)\n",
    "    X_resampled.append(resampled_sequence)\n",
    "X_resampled = np.array(X_resampled)\n",
    "X_resampled.shape\n",
    "```\n",
    "\n",
    "> h) Debido a que no hay conjunto de pruebas, y que es necesario para evaluar la calidad **final** del modelo, genérelo a través de la técnica *hold-out*\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=42)\n",
    "```\n",
    "\n",
    "> i) Realice un proceso de estándarizar los datos para ser trabajados adecuadamente. Recuerde que solo se debe ajustar (calcular media y desviación estándar) con el conjunto de entrenamiento.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "```\n",
    "> j) Realice una reducción de dimensionalidad a través de la técnica **PCA**, para representar los datos en $d = 2$ dimensiones. Recuerde que solo se debe ajustar (encontrar las componentes principales) con el conjunto de entrenamiento. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "d=2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(X_train)\n",
    "X_pca_train = pca_model.transform(X_train)\n",
    "X_pca_test = pca_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> k) Entrene un modelo de Regresión Logı́stica variando el parámetro de regularización $C$ construyendo un gráfico resumen del error en función de este hiper-parámetro. Además entrene un Perceptrón, variando el hiper-parámetro de regularización $\\alpha$ en el rango inverso que para la Regresión Logı́stica ¿Por qué? Contruya el mismo gráfico resumen, en función de $C$ o $\\alpha$. Compare y comente lo observado.\n",
    "```python\n",
    "Cs = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "alphas = [1/c for c in Cs]\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=c,max_iter=200)\n",
    "model = Perceptron(penalty='l2', alpha=a, max_iter=200)\n",
    "```\n",
    "\n",
    "> l) Genere otra representación de los datos a través de la técnica de reducción de dimensionalidad **ICA**, con dimensionalidad $d = 2$. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un *warning* explique el porqué. Visualice apropiadamente la proyección en 2 dimensiones. Vuelva a realizar el item k) pero para esta nueva representación.\n",
    "```python\n",
    "from sklearn.decomposition import FastICA\n",
    "ica_model = FastICA(n_components=d)\n",
    "ica_model.fit(X_train)\n",
    "X_ica_train = ica_model.transform(X_train)\n",
    "X_ica_test = ica_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> m) Experimente con diferentes dimensiones $d$ para la proyección de PCA e ICA con el propósito de obtener un modelo con menor error. Construya una tabla o gráfico resumen de los errores o *accuracy*, comente.\n",
    "\n",
    "> n) Realice otra reducción de dimensionalidad ahora a través de la técnica **LDA**, para representar los datos en $d = 2$ dimensiones. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un *warning* explique el porqué. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda_model = LDA(n_components=2)\n",
    "lda_model.fit(X_train,y_train)\n",
    "X_lda_train = lda_model.transform(X_train)\n",
    "X_lda_test = lda_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> o) Con el propósito de encontrar el mejor modelo vuelva a realizar el item k) en el nuevo espacio generado por la representación según las $d$ dimensiones de la proyección LDA. Esta nueva representación ¿mejora o empeora el desempeño? Explique.\n",
    "\n",
    "> p) Intente mejorar el desempeño de los algoritmos ya entrenados. Diseñe ahora sus propias cracterı́sticas (*feature crafting*) a partir de los datos brutos (secuencia de amplitudes), puede inspirarse en otros trabajos [[6]](#refs), [[7]](#refs)  si desea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "SAMPLE_RATE = 44100\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>time_series</th>\n",
       "      <th>len_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artifact__201012172012.wav</td>\n",
       "      <td>[1.0, -3.0, -1.0, -7.0, -9.0, -2.0, -6.0, -5.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artifact__201105040918.wav</td>\n",
       "      <td>[-2.0, 3.0, -4.0, 4.0, -3.0, 2.0, -1.0, 0.0, 0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artifact__201105041959.wav</td>\n",
       "      <td>[6.0, -4.0, -9.0, -1.0, -4.0, 1.0, -5.0, 2.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artifact__201105051017.wav</td>\n",
       "      <td>[-85.0, -198.0, -214.0, -173.0, -177.0, -206.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artifact__201105060108.wav</td>\n",
       "      <td>[53.0, -35.0, 47.0, 170.0, 340.0, 436.0, 535.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>artifact__201105061143.wav</td>\n",
       "      <td>[-2.0, 2.0, -2.0, 2.0, -2.0, 1.0, 1.0, -3.0, 3...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>artifact__201105190800.wav</td>\n",
       "      <td>[47.0, 70.0, 47.0, 58.0, 53.0, 45.0, 13.0, 21....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artifact__201105280851.wav</td>\n",
       "      <td>[605.0, 648.0, 473.0, 171.0, -203.0, -512.0, -...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>artifact__201106010559.wav</td>\n",
       "      <td>[-49.0, 0.0, 17.0, -43.0, 30.0, 9.0, -29.0, 50...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>artifact__201106010602.wav</td>\n",
       "      <td>[52.0, -1291.0, -1116.0, 101.0, 2429.0, 3776.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>artifact__201106021541.wav</td>\n",
       "      <td>[-1.0, 0.0, 1.0, -2.0, 3.0, -3.0, 3.0, -3.0, 3...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>artifact__201106030612.wav</td>\n",
       "      <td>[97.0, 152.0, 167.0, 168.0, 140.0, 113.0, 75.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>artifact__201106031558.wav</td>\n",
       "      <td>[-1390.0, -1358.0, -1372.0, -1377.0, -1396.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>artifact__201106040722.wav</td>\n",
       "      <td>[19664.0, 22367.0, 24463.0, 25936.0, 26723.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>artifact__201106040933.wav</td>\n",
       "      <td>[-5.0, -5.0, 2.0, -2.0, -3.0, -16.0, -2.0, 20....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>artifact__201106040947.wav</td>\n",
       "      <td>[6.0, 86.0, 21.0, 73.0, 52.0, 25.0, -53.0, -24...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>artifact__201106041452.wav</td>\n",
       "      <td>[-15901.0, -16151.0, -16527.0, -16737.0, -1654...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>artifact__201106050353.wav</td>\n",
       "      <td>[71.0, 75.0, 73.0, 87.0, 90.0, 101.0, 109.0, 1...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>artifact__201106061233.wav</td>\n",
       "      <td>[2373.0, 2373.0, 2374.0, 2373.0, 2385.0, 2387....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>artifact__201106070537.wav</td>\n",
       "      <td>[90.0, 97.0, 93.0, 82.0, 62.0, 37.0, 22.0, 27....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>artifact__201106070949.wav</td>\n",
       "      <td>[-2169.0, -2661.0, -1605.0, 952.0, 4714.0, 910...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>artifact__201106101314.wav</td>\n",
       "      <td>[-23.0, -127.0, -189.0, -259.0, -301.0, -362.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>artifact__201106101955.wav</td>\n",
       "      <td>[-3542.0, -2833.0, -2493.0, -2330.0, -2260.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>artifact__201106110909.wav</td>\n",
       "      <td>[-26.0, -29.0, -54.0, -17.0, -41.0, -53.0, -11...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>artifact__201106111119.wav</td>\n",
       "      <td>[-10054.0, -12117.0, -14014.0, -15866.0, -1760...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>artifact__201106121242.wav</td>\n",
       "      <td>[-2915.0, -2290.0, -1801.0, -1705.0, -1743.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>artifact__201106121445.wav</td>\n",
       "      <td>[-3.0, 3.0, -2.0, 2.0, -1.0, 0.0, 0.0, -1.0, 2...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>artifact__201106131834.wav</td>\n",
       "      <td>[3028.0, 4305.0, 5549.0, 6776.0, 7968.0, 9128....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>artifact__201106131835.wav</td>\n",
       "      <td>[-3489.0, -4399.0, -5297.0, -6197.0, -7087.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>artifact__201106141701.wav</td>\n",
       "      <td>[-35.0, 15.0, 38.0, -48.0, 46.0, 35.0, -23.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Aunlabelledtest__201105031730.wav</td>\n",
       "      <td>[46.0, 67.0, 103.0, 93.0, 112.0, 111.0, 123.0,...</td>\n",
       "      <td>334619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Aunlabelledtest__201106010807.wav</td>\n",
       "      <td>[-1818.0, -1599.0, -1370.0, -1145.0, -914.0, -...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Aunlabelledtest__201106030607.wav</td>\n",
       "      <td>[-1347.0, 1814.0, 4634.0, 6989.0, 8742.0, 9591...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Aunlabelledtest__201106031556.wav</td>\n",
       "      <td>[-1.0, 2.0, -3.0, 2.0, 0.0, -1.0, 1.0, -1.0, 1...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Aunlabelledtest__201106040930.wav</td>\n",
       "      <td>[-3.0, -21.0, -28.0, -29.0, -27.0, -19.0, -19....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Aunlabelledtest__201106061104.wav</td>\n",
       "      <td>[-877.0, -741.0, -644.0, -367.0, -359.0, -384....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Aunlabelledtest__201106061215.wav</td>\n",
       "      <td>[27.0, 21.0, 21.0, 17.0, 11.0, 0.0, -17.0, -28...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Aunlabelledtest__201106100606.wav</td>\n",
       "      <td>[-20.0, -12.0, -16.0, -17.0, -14.0, -21.0, -20...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Aunlabelledtest__201106111419.wav</td>\n",
       "      <td>[581.0, 578.0, 572.0, 573.0, 565.0, 558.0, 551...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Aunlabelledtest__201106120928.wav</td>\n",
       "      <td>[4.0, -3.0, 2.0, -2.0, 3.0, -4.0, 4.0, -3.0, 2...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Aunlabelledtest__201106130440.wav</td>\n",
       "      <td>[170.0, 157.0, 162.0, 139.0, 150.0, 164.0, 158...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Aunlabelledtest__201106150614.wav</td>\n",
       "      <td>[-2673.0, -109.0, 2185.0, 3466.0, 3446.0, 2443...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Aunlabelledtest__201106170857.wav</td>\n",
       "      <td>[1.0, -1.0, 0.0, 1.0, -1.0, 1.0, 0.0, -2.0, 3....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Aunlabelledtest__201106171155.wav</td>\n",
       "      <td>[-26297.0, -25721.0, -25059.0, -24314.0, -2345...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Aunlabelledtest__201106191034.wav</td>\n",
       "      <td>[-93.0, -44.0, -62.0, 57.0, -8.0, 3.0, -71.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Aunlabelledtest__201106211725.wav</td>\n",
       "      <td>[-414.0, -411.0, -412.0, -425.0, -419.0, -425....</td>\n",
       "      <td>287817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Aunlabelledtest__201106212102.wav</td>\n",
       "      <td>[-2.0, 1.0, 0.0, 0.0, -1.0, 2.0, -2.0, 1.0, 0....</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Aunlabelledtest__201108011111.wav</td>\n",
       "      <td>[-404.0, -442.0, -456.0, -482.0, -482.0, -494....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Aunlabelledtest__201108011113.wav</td>\n",
       "      <td>[519.0, 563.0, 585.0, 611.0, 618.0, 622.0, 618...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Aunlabelledtest__201108011116.wav</td>\n",
       "      <td>[280.0, 300.0, 317.0, 326.0, 332.0, 334.0, 328...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Aunlabelledtest__201108011117.wav</td>\n",
       "      <td>[-240.0, -251.0, -270.0, -270.0, -279.0, -272....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Aunlabelledtest__201108222222.wav</td>\n",
       "      <td>[-274.0, -287.0, -301.0, -295.0, -305.0, -289....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Aunlabelledtest__201108222225.wav</td>\n",
       "      <td>[-501.0, -533.0, -558.0, -573.0, -580.0, -577....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Aunlabelledtest__201108222228.wav</td>\n",
       "      <td>[591.0, 645.0, 693.0, 730.0, 765.0, 785.0, 808...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Aunlabelledtest__201108222234.wav</td>\n",
       "      <td>[-175.0, -191.0, -199.0, -208.0, -211.0, -215....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Aunlabelledtest__201108222241.wav</td>\n",
       "      <td>[-166.0, -173.0, -188.0, -184.0, -194.0, -185....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Aunlabelledtest__201108222244.wav</td>\n",
       "      <td>[-14035.0, -15001.0, -15710.0, -16178.0, -1638...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Aunlabelledtest__201108222247.wav</td>\n",
       "      <td>[376.0, 413.0, 429.0, 444.0, 456.0, 454.0, 454...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Aunlabelledtest__201108222254.wav</td>\n",
       "      <td>[-690.0, -745.0, -782.0, -817.0, -831.0, -842....</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Aunlabelledtest__201108222257.wav</td>\n",
       "      <td>[704.0, 760.0, 788.0, 818.0, 825.0, 828.0, 817...</td>\n",
       "      <td>349958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0           artifact__201012172012.wav   \n",
       "1           artifact__201105040918.wav   \n",
       "2           artifact__201105041959.wav   \n",
       "3           artifact__201105051017.wav   \n",
       "4           artifact__201105060108.wav   \n",
       "5           artifact__201105061143.wav   \n",
       "6           artifact__201105190800.wav   \n",
       "7           artifact__201105280851.wav   \n",
       "8           artifact__201106010559.wav   \n",
       "9           artifact__201106010602.wav   \n",
       "10          artifact__201106021541.wav   \n",
       "11          artifact__201106030612.wav   \n",
       "12          artifact__201106031558.wav   \n",
       "13          artifact__201106040722.wav   \n",
       "14          artifact__201106040933.wav   \n",
       "15          artifact__201106040947.wav   \n",
       "16          artifact__201106041452.wav   \n",
       "17          artifact__201106050353.wav   \n",
       "18          artifact__201106061233.wav   \n",
       "19          artifact__201106070537.wav   \n",
       "20          artifact__201106070949.wav   \n",
       "21          artifact__201106101314.wav   \n",
       "22          artifact__201106101955.wav   \n",
       "23          artifact__201106110909.wav   \n",
       "24          artifact__201106111119.wav   \n",
       "25          artifact__201106121242.wav   \n",
       "26          artifact__201106121445.wav   \n",
       "27          artifact__201106131834.wav   \n",
       "28          artifact__201106131835.wav   \n",
       "29          artifact__201106141701.wav   \n",
       "..                                 ...   \n",
       "146  Aunlabelledtest__201105031730.wav   \n",
       "147  Aunlabelledtest__201106010807.wav   \n",
       "148  Aunlabelledtest__201106030607.wav   \n",
       "149  Aunlabelledtest__201106031556.wav   \n",
       "150  Aunlabelledtest__201106040930.wav   \n",
       "151  Aunlabelledtest__201106061104.wav   \n",
       "152  Aunlabelledtest__201106061215.wav   \n",
       "153  Aunlabelledtest__201106100606.wav   \n",
       "154  Aunlabelledtest__201106111419.wav   \n",
       "155  Aunlabelledtest__201106120928.wav   \n",
       "156  Aunlabelledtest__201106130440.wav   \n",
       "157  Aunlabelledtest__201106150614.wav   \n",
       "158  Aunlabelledtest__201106170857.wav   \n",
       "159  Aunlabelledtest__201106171155.wav   \n",
       "160  Aunlabelledtest__201106191034.wav   \n",
       "161  Aunlabelledtest__201106211725.wav   \n",
       "162  Aunlabelledtest__201106212102.wav   \n",
       "163  Aunlabelledtest__201108011111.wav   \n",
       "164  Aunlabelledtest__201108011113.wav   \n",
       "165  Aunlabelledtest__201108011116.wav   \n",
       "166  Aunlabelledtest__201108011117.wav   \n",
       "167  Aunlabelledtest__201108222222.wav   \n",
       "168  Aunlabelledtest__201108222225.wav   \n",
       "169  Aunlabelledtest__201108222228.wav   \n",
       "170  Aunlabelledtest__201108222234.wav   \n",
       "171  Aunlabelledtest__201108222241.wav   \n",
       "172  Aunlabelledtest__201108222244.wav   \n",
       "173  Aunlabelledtest__201108222247.wav   \n",
       "174  Aunlabelledtest__201108222254.wav   \n",
       "175  Aunlabelledtest__201108222257.wav   \n",
       "\n",
       "                                           time_series  len_series  \n",
       "0    [1.0, -3.0, -1.0, -7.0, -9.0, -2.0, -6.0, -5.0...      396900  \n",
       "1    [-2.0, 3.0, -4.0, 4.0, -3.0, 2.0, -1.0, 0.0, 0...      396900  \n",
       "2    [6.0, -4.0, -9.0, -1.0, -4.0, 1.0, -5.0, 2.0, ...      396900  \n",
       "3    [-85.0, -198.0, -214.0, -173.0, -177.0, -206.0...      396900  \n",
       "4    [53.0, -35.0, 47.0, 170.0, 340.0, 436.0, 535.0...      396900  \n",
       "5    [-2.0, 2.0, -2.0, 2.0, -2.0, 1.0, 1.0, -3.0, 3...      396900  \n",
       "6    [47.0, 70.0, 47.0, 58.0, 53.0, 45.0, 13.0, 21....      396900  \n",
       "7    [605.0, 648.0, 473.0, 171.0, -203.0, -512.0, -...      396900  \n",
       "8    [-49.0, 0.0, 17.0, -43.0, 30.0, 9.0, -29.0, 50...      396900  \n",
       "9    [52.0, -1291.0, -1116.0, 101.0, 2429.0, 3776.0...      396900  \n",
       "10   [-1.0, 0.0, 1.0, -2.0, 3.0, -3.0, 3.0, -3.0, 3...      396900  \n",
       "11   [97.0, 152.0, 167.0, 168.0, 140.0, 113.0, 75.0...      396900  \n",
       "12   [-1390.0, -1358.0, -1372.0, -1377.0, -1396.0, ...      396900  \n",
       "13   [19664.0, 22367.0, 24463.0, 25936.0, 26723.0, ...      396900  \n",
       "14   [-5.0, -5.0, 2.0, -2.0, -3.0, -16.0, -2.0, 20....      396900  \n",
       "15   [6.0, 86.0, 21.0, 73.0, 52.0, 25.0, -53.0, -24...      396900  \n",
       "16   [-15901.0, -16151.0, -16527.0, -16737.0, -1654...      396900  \n",
       "17   [71.0, 75.0, 73.0, 87.0, 90.0, 101.0, 109.0, 1...      396900  \n",
       "18   [2373.0, 2373.0, 2374.0, 2373.0, 2385.0, 2387....      396900  \n",
       "19   [90.0, 97.0, 93.0, 82.0, 62.0, 37.0, 22.0, 27....      396900  \n",
       "20   [-2169.0, -2661.0, -1605.0, 952.0, 4714.0, 910...      396900  \n",
       "21   [-23.0, -127.0, -189.0, -259.0, -301.0, -362.0...      396900  \n",
       "22   [-3542.0, -2833.0, -2493.0, -2330.0, -2260.0, ...      396900  \n",
       "23   [-26.0, -29.0, -54.0, -17.0, -41.0, -53.0, -11...      396900  \n",
       "24   [-10054.0, -12117.0, -14014.0, -15866.0, -1760...      396900  \n",
       "25   [-2915.0, -2290.0, -1801.0, -1705.0, -1743.0, ...      396900  \n",
       "26   [-3.0, 3.0, -2.0, 2.0, -1.0, 0.0, 0.0, -1.0, 2...      396900  \n",
       "27   [3028.0, 4305.0, 5549.0, 6776.0, 7968.0, 9128....      396900  \n",
       "28   [-3489.0, -4399.0, -5297.0, -6197.0, -7087.0, ...      396900  \n",
       "29   [-35.0, 15.0, 38.0, -48.0, 46.0, 35.0, -23.0, ...      396900  \n",
       "..                                                 ...         ...  \n",
       "146  [46.0, 67.0, 103.0, 93.0, 112.0, 111.0, 123.0,...      334619  \n",
       "147  [-1818.0, -1599.0, -1370.0, -1145.0, -914.0, -...      396900  \n",
       "148  [-1347.0, 1814.0, 4634.0, 6989.0, 8742.0, 9591...      396900  \n",
       "149  [-1.0, 2.0, -3.0, 2.0, 0.0, -1.0, 1.0, -1.0, 1...      396900  \n",
       "150  [-3.0, -21.0, -28.0, -29.0, -27.0, -19.0, -19....      396900  \n",
       "151  [-877.0, -741.0, -644.0, -367.0, -359.0, -384....      396900  \n",
       "152  [27.0, 21.0, 21.0, 17.0, 11.0, 0.0, -17.0, -28...      396900  \n",
       "153  [-20.0, -12.0, -16.0, -17.0, -14.0, -21.0, -20...      396900  \n",
       "154  [581.0, 578.0, 572.0, 573.0, 565.0, 558.0, 551...      396900  \n",
       "155  [4.0, -3.0, 2.0, -2.0, 3.0, -4.0, 4.0, -3.0, 2...      396900  \n",
       "156  [170.0, 157.0, 162.0, 139.0, 150.0, 164.0, 158...      396900  \n",
       "157  [-2673.0, -109.0, 2185.0, 3466.0, 3446.0, 2443...      396900  \n",
       "158  [1.0, -1.0, 0.0, 1.0, -1.0, 1.0, 0.0, -2.0, 3....      396900  \n",
       "159  [-26297.0, -25721.0, -25059.0, -24314.0, -2345...      396900  \n",
       "160  [-93.0, -44.0, -62.0, 57.0, -8.0, 3.0, -71.0, ...      396900  \n",
       "161  [-414.0, -411.0, -412.0, -425.0, -419.0, -425....      287817  \n",
       "162  [-2.0, 1.0, 0.0, 0.0, -1.0, 2.0, -2.0, 1.0, 0....      396900  \n",
       "163  [-404.0, -442.0, -456.0, -482.0, -482.0, -494....      349958  \n",
       "164  [519.0, 563.0, 585.0, 611.0, 618.0, 622.0, 618...      349958  \n",
       "165  [280.0, 300.0, 317.0, 326.0, 332.0, 334.0, 328...      349958  \n",
       "166  [-240.0, -251.0, -270.0, -270.0, -279.0, -272....      349958  \n",
       "167  [-274.0, -287.0, -301.0, -295.0, -305.0, -289....      349958  \n",
       "168  [-501.0, -533.0, -558.0, -573.0, -580.0, -577....      349958  \n",
       "169  [591.0, 645.0, 693.0, 730.0, 765.0, 785.0, 808...      349958  \n",
       "170  [-175.0, -191.0, -199.0, -208.0, -211.0, -215....      349958  \n",
       "171  [-166.0, -173.0, -188.0, -184.0, -194.0, -185....      349958  \n",
       "172  [-14035.0, -15001.0, -15710.0, -16178.0, -1638...      349958  \n",
       "173  [376.0, 413.0, 429.0, 444.0, 456.0, 454.0, 454...      349958  \n",
       "174  [-690.0, -745.0, -782.0, -817.0, -831.0, -842....      349958  \n",
       "175  [704.0, 760.0, 788.0, 818.0, 825.0, 828.0, 817...      349958  \n",
       "\n",
       "[176 rows x 3 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelledtest')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='./heartbeat-sounds/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series']=new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))\n",
    "\n",
    "\n",
    "new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     file_name  \\\n",
      "40  extrahls__201101070953.wav   \n",
      "41  extrahls__201101091153.wav   \n",
      "42  extrahls__201101152255.wav   \n",
      "43  extrahls__201101160804.wav   \n",
      "44  extrahls__201101160808.wav   \n",
      "45  extrahls__201101161027.wav   \n",
      "46  extrahls__201101241423.wav   \n",
      "47  extrahls__201101241433.wav   \n",
      "48  extrahls__201102070251.wav   \n",
      "49  extrahls__201102071835.wav   \n",
      "50  extrahls__201102241217.wav   \n",
      "51  extrahls__201103150114.wav   \n",
      "52  extrahls__201103170134.wav   \n",
      "53  extrahls__201103182227.wav   \n",
      "54  extrahls__201103200218.wav   \n",
      "55  extrahls__201104021355.wav   \n",
      "56  extrahls__201104140118.wav   \n",
      "57  extrahls__201104270458.wav   \n",
      "58  extrahls__201104270459.wav   \n",
      "59    murmur__201101051104.wav   \n",
      "60    murmur__201101051108.wav   \n",
      "61    murmur__201101051114.wav   \n",
      "62    murmur__201101180902.wav   \n",
      "63    murmur__201102051443.wav   \n",
      "64    murmur__201102052338.wav   \n",
      "65    murmur__201103291548.wav   \n",
      "66    murmur__201104021355.wav   \n",
      "67    murmur__201104241315.wav   \n",
      "68    murmur__201104291843.wav   \n",
      "69    murmur__201106141148.wav   \n",
      "70    murmur__201108222221.wav   \n",
      "71    murmur__201108222223.wav   \n",
      "72    murmur__201108222224.wav   \n",
      "73    murmur__201108222226.wav   \n",
      "74    murmur__201108222227.wav   \n",
      "\n",
      "                                          time_series  len_series  \\\n",
      "40  [37.0, 25.0, 28.0, 28.0, 5.0, 3.0, 22.0, 27.0,...      391787   \n",
      "41  [0.0, 14.0, 18.0, 0.0, -3.0, -5.0, -4.0, -24.0...      396900   \n",
      "42  [0.0, 0.0, 8.0, 1.0, 5.0, 7.0, 0.0, 8.0, 2.0, ...      353954   \n",
      "43  [-167.0, -197.0, -211.0, -193.0, -188.0, -185....      309467   \n",
      "44  [475.0, 462.0, 442.0, 463.0, 466.0, 482.0, 462...      271970   \n",
      "45  [220.0, 191.0, 171.0, 138.0, 202.0, 196.0, 211...      262646   \n",
      "46  [-156.0, -147.0, -146.0, -139.0, -137.0, -128....      396900   \n",
      "47  [-9.0, -13.0, -9.0, -8.0, -1.0, 6.0, -1.0, 2.0...      396900   \n",
      "48  [-9.0, -10.0, -15.0, -9.0, -10.0, -5.0, -5.0, ...      353414   \n",
      "49  [-12.0, -10.0, 6.0, 3.0, 15.0, 6.0, 15.0, 11.0...      346781   \n",
      "50  [-1350.0, -1373.0, -1411.0, -1434.0, -1448.0, ...      396900   \n",
      "51  [-271.0, -246.0, -260.0, -245.0, -221.0, -192....      396900   \n",
      "52  [3.0, 1.0, -4.0, 0.0, -3.0, -10.0, 3.0, 2.0, 6...      347518   \n",
      "53  [-4.0, 3.0, 1.0, 5.0, 4.0, 5.0, 2.0, -2.0, 4.0...      396900   \n",
      "54  [329.0, 323.0, 339.0, 333.0, 372.0, 406.0, 451...      396900   \n",
      "55  [-26.0, -29.0, -35.0, -15.0, 12.0, 20.0, 4.0, ...       41294   \n",
      "56  [10.0, -1.0, -4.0, -12.0, -14.0, -17.0, -15.0,...       85880   \n",
      "57  [-995.0, -947.0, -924.0, -859.0, -872.0, -854....      142681   \n",
      "58  [2332.0, 2331.0, 2316.0, 2311.0, 2267.0, 2236....       72555   \n",
      "59  [-241.0, -230.0, -226.0, -223.0, -208.0, -205....      391787   \n",
      "60  [-85.0, -100.0, -88.0, -92.0, -107.0, -96.0, -...      391787   \n",
      "61  [1693.0, 1663.0, 1642.0, 1628.0, 1573.0, 1552....      391787   \n",
      "62  [-1944.0, -1931.0, -1928.0, -1905.0, -1905.0, ...      354318   \n",
      "63  [62.0, 41.0, 70.0, 34.0, 14.0, -59.0, -67.0, -...      300715   \n",
      "64  [366.0, 359.0, 356.0, 340.0, 335.0, 337.0, 338...      396900   \n",
      "65  [4546.0, 4542.0, 4541.0, 4544.0, 4544.0, 4547....      330934   \n",
      "66  [-26.0, -31.0, -32.0, -19.0, 15.0, 20.0, 2.0, ...       41294   \n",
      "67  [-20.0, -3.0, 6.0, 21.0, 13.0, 60.0, 81.0, 84....      396900   \n",
      "68  [52.0, 42.0, 27.0, 23.0, 4.0, -1.0, -5.0, 32.0...      212865   \n",
      "69  [123.0, 90.0, 88.0, 85.0, 82.0, 66.0, 30.0, 5....      263126   \n",
      "70  [-43.0, -47.0, -54.0, -57.0, -64.0, -63.0, -71...      349958   \n",
      "71  [715.0, 772.0, 831.0, 870.0, 902.0, 930.0, 941...      349958   \n",
      "72  [652.0, 692.0, 726.0, 743.0, 755.0, 750.0, 745...      349958   \n",
      "73  [-1326.0, -1439.0, -1518.0, -1587.0, -1631.0, ...      349958   \n",
      "74  [-2054.0, -2170.0, -2224.0, -2238.0, -2215.0, ...      349958   \n",
      "\n",
      "             target  \n",
      "40           murmur  \n",
      "41  normal/extrahls  \n",
      "42  normal/extrahls  \n",
      "43  normal/extrahls  \n",
      "44  normal/extrahls  \n",
      "45  normal/extrahls  \n",
      "46  normal/extrahls  \n",
      "47  normal/extrahls  \n",
      "48  normal/extrahls  \n",
      "49  normal/extrahls  \n",
      "50  normal/extrahls  \n",
      "51  normal/extrahls  \n",
      "52  normal/extrahls  \n",
      "53  normal/extrahls  \n",
      "54  normal/extrahls  \n",
      "55           murmur  \n",
      "56  normal/extrahls  \n",
      "57  normal/extrahls  \n",
      "58  normal/extrahls  \n",
      "59           murmur  \n",
      "60           murmur  \n",
      "61           murmur  \n",
      "62  normal/extrahls  \n",
      "63  normal/extrahls  \n",
      "64           murmur  \n",
      "65  normal/extrahls  \n",
      "66           murmur  \n",
      "67           murmur  \n",
      "68  normal/extrahls  \n",
      "69           murmur  \n",
      "70           murmur  \n",
      "71           murmur  \n",
      "72           murmur  \n",
      "73           murmur  \n",
      "74           murmur  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]\n",
    "print(new_df[40:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Análisis de emociones en *tweets*\n",
    "\n",
    "El análisis de emociones o sentimientos se refiere al proceso de extraer información acerca de la actitud que una persona (o grupo de ellas) manifiesta, en un determinado medio o formato digital, con respecto a un tópico o contexto de comunicación. Uno de los casos más estudiados corresponde a determinar la polaridad de un trozo de texto, es decir, clasificar una determinada evaluación escrita (review ), en que una persona manifiesta una opinión, como positiva, negativa o neutral. Esto también ha sido extendido a otros medios, como lo es analizar la polaridad de textos en redes sociales.\n",
    "\n",
    "<img src=\"https://image.flaticon.com/sprites/new_packs/132222-color-emotions-assets.png\" width=\"40%\" />\n",
    "\n",
    "\n",
    "\n",
    "Para esta actividad se trabajará con un datasets de tweets ofrecidos por CrowdFlower[[8]](#refs). Cada *tweet* está\n",
    "asociado a una emoción en particular, donde el conjunto de emociones se trabajarán como mutuamente excluyentes, siendo un problema de múltiples clases.\n",
    "\n",
    "Los datos pueden ser descargados ejecutando el siguiente código en sistema Unix:\n",
    "```\n",
    "wget https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv\n",
    "```\n",
    "\n",
    "Para aumentar la eficacia de las caracterı́sticas extraı́das es conveniente ejecutar algunas técnicas de pre-procesamiento básicas.\n",
    "\n",
    "> a) Construya un dataframe con los datos a analizar. Determine cuántas clases existen, cuántos registros por clase y describa el dataset.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./emotionanalysis/text_emotion.csv')\n",
    "```\n",
    "\n",
    "> b) Construya un conjunto de entrenamiento y otro de pruebas, a través de una máscara aleatoria, para verificar los resultados de los algoritmos. Genere un conjunto de validación si estima conveniente.\n",
    "```python\n",
    "import numpy as np\n",
    "np.seed(70)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "```\n",
    "\n",
    "> c) Construya las representaciones de los datos con los que trabajará, ya sea para las entradas de los modelos como para las salidas. Recuerde que tendrá que codificar las distintas clases como valores numéricos enteros. \n",
    "\n",
    "> d) Entrene y compare al menos 4 de los diferentes clasificadores vistos en clases para clasificación (por ejemplo: Navie Bayes, Multinomial Naive Bayes, LDA, QDA, Regresión logı́stica y Perceptrón). Recuerde que algunos son extendidos por defecto a múltiples clases para detectar emociones en cada *tweet*, sin embargo, otros deben ser extentidos a través de otras técnicas, tal como *One vs One* y *One vs All/Rest*. Muestre tabla o gráfico resumen.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#example\n",
    "classif = OneVsRestClassifier(model)\n",
    "classif.fit(X, Y)\n",
    "#or for LR\n",
    "LogisticRegression(multi_class= 'ovr' or 'multinomial')\n",
    "```\n",
    "\n",
    "> e) Utilice la técnica de ECOC (*Error-Correcting Output-Code*) para extender a multiclases algunos de los clasificadores utilizados en d). Comente lo que hace la técnica y los resultados observados.\n",
    "\n",
    "\n",
    "> f) Evalúe la métrica de *accuracy* sobre el conjunto de pruebas del mejor clasificador encontrado.  \n",
    "*Recuerde que puede acudir a otras métricas para tener otras visiones de lo que está haciendo el modelo de aprendizaje*\n",
    "\n",
    "> g) Intente mejorar su resultado considerablemente a través de alguna mejora novedosa. Se espera que supere el 35% de *accuracy*.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\"> Una opción es cambiar considerablemente la representación de los textos, ya sea con Tf-Idf, word2vec[[9]](#refs) , doc2vec[[10]](#refs) , otros. </div>\n",
    "\n",
    "<div class=\"alert alert-warning\"> Otra opción es hacer una clasificación por grupos, es decir, agrupar emociones para ir distinguiendo y bajar la granulidad de la clasificación. Como una clasificación jerárquica en modo árbol.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Hastie, T.; Tibshirani, R., Friedman, J. (2009), *The Elements of Statistical Learning*, Second Edition.\n",
    "Springer New York Inc.  \n",
    "[2] Ethem Alpaydin. *Machine Learning*. 2014.  \n",
    "[3] Bentley, P. and Nordehn, G. and Coimbra, M. and Mannor (2011) , Classifying Heart Sounds Challenge,\n",
    "CHSC2011, http://www.peterjbentley.com/heartchallenge/index.html  \n",
    "[4] https://www.kaggle.com/toregil/new-labels-for-set-a  \n",
    "[5] https://en.wikipedia.org/wiki/Fourier transform  \n",
    "[6] https://www.kaggle.com/primaryobjects/voicegender/data  \n",
    "[7] Gamit, M. R., Dhameliya, P. K., & Bhatt, N. S. (2015). Classification Techniques for Speech Recognition:\n",
    "A Review. vol, 5, 58-63.  \n",
    "[8] www.figure-eight.com/  \n",
    "[9] https://machinelearningmastery.com/develop-word-embeddings-python-gensim/, https://radimrehurek.com/gensim/models/word2vec.html or https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/  \n",
    "[10] https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-6-doc2vec-603f11832504"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
